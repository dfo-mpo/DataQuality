{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run everything in the **Setup** section. \n",
    "    - Make sure to change the working directory to **your** working directory. The code for this is already there.\n",
    "    - Make sure the Excel document for logging the scores also exists in your working directory, and that the file name is correct.\n",
    "\n",
    "2. Determine *if the test needs to be run* by having a good understanding of what each test is doing. \n",
    "    - Please refer to this document [here](https://086gc.sharepoint.com/:x:/r/sites/PacificSalmonTeam/Shared%20Documents/General/02%20-%20PSSI%20Secretariat%20Teams/04%20-%20Strategic%20Salmon%20Data%20Policy%20and%20Analytics/02%20-%20Data%20Governance/00%20-%20Projects/10%20-%20Data%20Quality/Presentation/DQP%20Demo.xlsx?d=wc15abe6743954df980a05f09fe99a560&csf=1&web=1&e=CJeb6h)\n",
    "\n",
    "3. Some requirements for the datasets:\n",
    "    - The data must be on the **first sheet** in the Excel document.\n",
    "    - The **first row** must be the column names. \n",
    "    - The test won't run if the Excel file is open\n",
    "\n",
    "4. After running all the tests, the Excel document for logging the scores can be uploaded to Sharepoint using the function \"Saving the file to sharepoint\". \n",
    "\n",
    "Note: The Output Reports are used for when a data steward is asking about why their dataset gets a certain score. If the metric is not in Output Reports, then running the test itself will generate an output that can be put into a report.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run everything in the set up, and double check the working directory so that the data can be read from that same directory.\n",
    "\n",
    "All of these functions are used in the process of calculating data quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from datetime import datetime\n",
    "import nbformat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support functions to allow running cells from other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_selected_cells(notebook_path, cell_indices):       \n",
    "    # Load the notebook       \n",
    "    with open(notebook_path) as f:           \n",
    "        nb = nbformat.read(f, as_version=4)   \n",
    "\n",
    "    # Get the cells to run       \n",
    "    selected_cells = [nb.cells[i] for i in cell_indices]   \n",
    "\n",
    "    # Execute the selected cells       \n",
    "    for cell in selected_cells:           \n",
    "        if cell.cell_type == 'code':               \n",
    "            exec(cell.source)\n",
    "\n",
    "def run_selected_cells_from_util(util_folder, notebook_name, cell_indices):       \n",
    "    notebook_path = os.path.join(util_folder, notebook_name)       \n",
    "    run_selected_cells(notebook_path, cell_indices)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to set to the correct working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory to the same place where you saved the test datasets\n",
    "# os.chdir('C:/Users/luos/OneDrive - DFO-MPO/Python') #change directory\n",
    "os.getcwd()  # check where the directory is (and whether the change was successful or not)\n",
    "GLOBAL_USER = \"OnakD\"\n",
    "GLOBAL_DATASET = \"CU Sampling Sites\"\n",
    "GLOBAL_DATAFILE = \"Conservation_Unit_Data_20220902.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to read either csv or xlsx data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 0: Reading the dataset file\n",
    "def read_data(dataset_path):\n",
    "    _, file_extension = os.path.splitext(dataset_path)\n",
    "    if file_extension == \".csv\":\n",
    "        df = pd.read_csv(\n",
    "            dataset_path, encoding=\"cp1252\"\n",
    "        )  # sometimes if the function has issue reading a csv file, include: , encoding = 'cp1252')\n",
    "    elif file_extension == \".xlsx\":\n",
    "        df = pd.read_excel(dataset_path)\n",
    "    else:\n",
    "        print(\"Unsupported file type\")\n",
    "        df = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to log the scores into an xlsx file (already created, existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log a new row into the DQS_Log_XX.xlsx file\n",
    "def log_score(test_name, dataset_name, score, selected_columns, threshold=None):\n",
    "    # Convert score to a percentage\n",
    "    percentage_score = score\n",
    "\n",
    "    # Load the Excel file into a DataFrame\n",
    "    log_file = \"DQS_Log_Beta.xlsx\"\n",
    "\n",
    "    # Set threshold to \"No threshold\" if it is not provided\n",
    "    if threshold is None:\n",
    "        threshold_value = \"no threshold\"\n",
    "    else:\n",
    "        threshold_value = threshold\n",
    "\n",
    "    # If selected_columns is None, assume \"All\" was tested\n",
    "    if selected_columns is None:\n",
    "        columns_tested = \"All columns\"\n",
    "    else:\n",
    "        # Convert selected_columns list to a string if specific columns are provided\n",
    "        columns_tested = \", \".join(selected_columns)\n",
    "\n",
    "    # Try loading the existing Excel file\n",
    "    try:\n",
    "        df = read_data(log_file)\n",
    "    except FileNotFoundError:\n",
    "        # Create an empty DataFrame if file doesn't exist (shouldn't be the case if you already created it)\n",
    "        df = pd.DataFrame(\n",
    "            columns=[\"Dataset\", \"Test\", \"Threshold\", \"Date_Calculated\", \"Score\"]\n",
    "        )\n",
    "\n",
    "    # Prepare the new row as a DataFrame\n",
    "    new_row = pd.DataFrame(\n",
    "        {\n",
    "            \"Dataset\": [dataset_name],\n",
    "            \"Columns_Tested\": [columns_tested],  # Add the list of columns tested\n",
    "            \"Test\": [test_name],\n",
    "            \"Date_Calculated\": [datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")],\n",
    "            \"Threshold\": [threshold_value],\n",
    "            \"Score\": [percentage_score],\n",
    "            \"User\": GLOBAL_USER\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Append the new row to the DataFrame\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame back to the Excel file\n",
    "    df.to_excel(log_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to extract dataset name from a path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_name(dataset_path):\n",
    "    # Extract the file name from the path (e.g., 'Dataset_A.csv')\n",
    "    file_name = os.path.basename(dataset_path)\n",
    "    # Split the file name to remove the extension (e.g., 'Dataset_A')\n",
    "    dataset_name = os.path.splitext(file_name)[0]\n",
    "    return dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consistency Type 1 (C1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate consistency score of a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is best run on CSV data where the column names are in the first row. It can also accept files that are in xlsx formats but it will only take data from the first sheet if there are more than one sheet in the excel file.\n",
    "\n",
    "Limitations: It will not check for differences in capitalization of the same word (since all the words will be changed to lower case before the similarity score is calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run utils for C1 \n",
    "run_selected_cells_from_util('utils', 'consistancy_utils.ipynb', [1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the dataset by changing the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OnakD\\AppData\\Local\\Temp\\1\\ipykernel_14756\\3180660.py:5: DtypeWarning: Columns (27,28,29,30,31,32,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is too large for this test, out of memory!\n",
      "Unable to allocate 719. GiB for an array with shape (310751, 310751) and data type float64\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    datafilepath = f\"C:/Users/{GLOBAL_USER}/OneDrive - DFO-MPO/04 - Strategic Salmon Data Policy and Analytics/07 - Data Products & Data/21 - Transitory Files/{GLOBAL_DATASET}/{GLOBAL_DATAFILE}\"\n",
    "    # Test Consistency Calculations\n",
    "\n",
    "    processed_df = process_and_calculate_similarity(\n",
    "        dataset_path=datafilepath,\n",
    "        column_names=[\"DESCR\",\"ESTIMATE_CLASSIFICATION\",\"ESTIMATE_METHOD\",\"ESTIMATE_STAGE\",\"SEN_PRESENCE_ADULT\", \"SEN_PRESENCE_JACK\",\n",
    "    \"POPULATION\",\"RUN_TYPE\",\"SEN_NUSEDS1_ENUM_METHOD1\",\"SEN_NUSEDS1_ENUM_METHOD2\",\"SEN_NUSEDS1_ENUM_METHOD3\",\"SEN_NUSEDS1_ENUM_METHOD4\",\n",
    "    \"GEOGRAPHICAL_EXTNT_OF_ESTIMATE\",\"CU_NAME\",\"CU_INDEX\",\"CU_TYPE\"] ,\n",
    "        threshold=0.91\n",
    "    )\n",
    "\n",
    "    # processed_df['Overall Consistency Score'].min()\n",
    "    processed_df\n",
    "except MemoryError as e:\n",
    "    print(\"Dataset is too large for this test, out of memory!\")\n",
    "    print(e)\n",
    "except KeyError:\n",
    "    print(\"Issue with column names, are you sure you entered them correctly?\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Did not find dataset, make sure you have provided the correct name.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consistency Type 2 (C2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate consistency score of datasets with a reference list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compared columns in question must be identical to the ref list, otherwise they will be penalized more harshly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run utils for C2\n",
    "run_selected_cells_from_util('utils', 'consistancy_utils.ipynb', [2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the dataset by changing the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_mapping = {\n",
    "#     \"STOCK_CU_NAME\": \"CU_Display\",\n",
    "#     \"STOCK_CU_INDEX\": \"FULL_CU_IN\",\n",
    "# }  # the pattern for comparison is 'dataset column' : 'reference column'\n",
    "# process_and_calculate_similarity_ref(\n",
    "#     dataset_path=\"data/test/2024-03-28 1_qryThermal_NatEmerg.xlsx\",\n",
    "#     column_mapping=column_mapping,\n",
    "#     ref_dataset_path=\"data/Pacific Salmon Population Unit Crosswalk_Final_20240513.xlsx\",\n",
    "#     threshold=1,\n",
    "#     Stop_Words=[\"\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Type 1 (A1, Mixed Data Types, Symbols in Numerics) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test whether there are symbols in numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run utils for A1\n",
    "run_selected_cells_from_util('utils', 'accuracy_utils.ipynb', [1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the dataset by changing the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OnakD\\AppData\\Local\\Temp\\1\\ipykernel_14756\\3180660.py:5: DtypeWarning: Columns (27,28,29,30,31,32,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    datafilepath = f\"C:/Users/{GLOBAL_USER}/OneDrive - DFO-MPO/04 - Strategic Salmon Data Policy and Analytics/07 - Data Products & Data/21 - Transitory Files/{GLOBAL_DATASET}/{GLOBAL_DATAFILE}\"\n",
    "    accuracy_score(\n",
    "\n",
    "        dataset_path=datafilepath,\n",
    "\n",
    "        selected_columns=[\"ACT_ID\",\"ANALYSIS_YR\",\"STREAM_ID\",\"SPL_ID\",\"NATURAL_ADULT_SPAWNERS\",\"NATURAL_JACK_SPAWNERS\",\"NATURAL_SPAWNERS_TOTAL\",\n",
    " \"ADULT_BROODSTOCK_REMOVALS\",\"JACK_BROODSTOCK_REMOVALS\",\"TOTAL_BROODSTOCK_REMOVALS\",\"OTHER_REMOVALS\",\"TOTAL_RETURN_TO_RIVER\",\"UNSPECIFIED_RETURN\",\"NO_INSPECTIONS_USED\", \"MAX_ESTIMATE\",\"EFFECTIVE_FEMALES\",\"WEIGHTED_PCT_SPAWN\",\"OTHER_ADULT_REMOVALS\",\"OTHER_JACK_REMOVALS\",\"TOT_ADULT_RET_RIVER\",\"TOT_JACK_RET_RIVER\",\n",
    "\"JUV_PRES_TYP\",\"POP_ID\",\"SBJ_ID\"],\n",
    "\n",
    "    )\n",
    "except KeyError:\n",
    "    print(\"Issue with column names, are you sure you entered them correctly?\")\n",
    "except Exception as e:\n",
    "    print(\"Test failed!\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Type 2 (A2 Outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run utils for A2\n",
    "run_selected_cells_from_util('utils', 'accuracy_utils.ipynb', [2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OnakD\\AppData\\Local\\Temp\\1\\ipykernel_14756\\3180660.py:5: DtypeWarning: Columns (27,28,29,30,31,32,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "try:    \n",
    "    datafilepath = f\"C:/Users/{GLOBAL_USER}/OneDrive - DFO-MPO/04 - Strategic Salmon Data Policy and Analytics/07 - Data Products & Data/21 - Transitory Files/{GLOBAL_DATASET}/{GLOBAL_DATAFILE}\"\n",
    "    find_outliers_iqr(\n",
    "        dataset_path=datafilepath,\n",
    "        selected_columns = [\"ACT_ID\",\"ANALYSIS_YR\",\"STREAM_ID\",\"SPL_ID\",\"NATURAL_ADULT_SPAWNERS\",\"NATURAL_JACK_SPAWNERS\",\"NATURAL_SPAWNERS_TOTAL\",\n",
    " \"ADULT_BROODSTOCK_REMOVALS\",\"JACK_BROODSTOCK_REMOVALS\",\"TOTAL_BROODSTOCK_REMOVALS\",\"OTHER_REMOVALS\",\"TOTAL_RETURN_TO_RIVER\",\"UNSPECIFIED_RETURN\",\"NO_INSPECTIONS_USED\", \"MAX_ESTIMATE\",\"EFFECTIVE_FEMALES\",\"WEIGHTED_PCT_SPAWN\",\"OTHER_ADULT_REMOVALS\",\"OTHER_JACK_REMOVALS\",\"TOT_ADULT_RET_RIVER\",\"TOT_JACK_RET_RIVER\",\n",
    "\"JUV_PRES_TYP\",\"POP_ID\",\"SBJ_ID\"],\n",
    "        threshold=0.85,\n",
    "        minimum_score=0.80,\n",
    "    )\n",
    "\n",
    "except KeyError:\n",
    "    print(\"Issue with column names, are you sure you entered them correctly?\")\n",
    "except Exception as e:\n",
    "    print(\"Test failed!\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Type 3 (A3 Duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run utils for A3\n",
    "run_selected_cells_from_util('utils', 'accuracy_utils.ipynb', [3]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OnakD\\AppData\\Local\\Temp\\1\\ipykernel_14756\\3180660.py:5: DtypeWarning: Columns (27,28,29,30,31,32,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "Empty DataFrame\n",
      "Columns: [ACT_ID, DESCR, ANALYSIS_YR, STREAM_ID, AREA, SPECIES, SEN_STATUS, ESTIMATE_CLASSIFICATION, ESTIMATE_METHOD, WATERSHED_CDE, ESTIMATE_STAGE, SPL_ID, SEN_PRESENCE_ADULT, SEN_PRESENCE_JACK, NATURAL_ADULT_SPAWNERS, NATURAL_JACK_SPAWNERS, NATURAL_SPAWNERS_TOTAL, ADULT_BROODSTOCK_REMOVALS, JACK_BROODSTOCK_REMOVALS, TOTAL_BROODSTOCK_REMOVALS, OTHER_REMOVALS, TOTAL_RETURN_TO_RIVER, UNSPECIFIED_RETURN, NO_INSPECTIONS_USED, POPULATION, MAX_ESTIMATE, RUN_TYPE, SEN_NUSEDS1_ENUM_METHOD1, SEN_NUSEDS1_ENUM_METHOD2, SEN_NUSEDS1_ENUM_METHOD3, SEN_NUSEDS1_ENUM_METHOD4, SEN_NUSEDS1_ENUM_METHOD5, SEN_NUSEDS1_ENUM_METHOD6, EFFECTIVE_FEMALES, WEIGHTED_PCT_SPAWN, OTHER_ADULT_REMOVALS, OTHER_JACK_REMOVALS, TOT_ADULT_RET_RIVER, TOT_JACK_RET_RIVER, JUV_PRES_TYP, GEOGRAPHICAL_EXTNT_OF_ESTIMATE, POP_ID, CU_NAME, CU_INDEX, CU_TYPE, SPECIES_QUALIFIED, SBJ_ID]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 47 columns]\n",
      "\n",
      "Duplication Score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    datafilepath = f\"C:/Users/{GLOBAL_USER}/OneDrive - DFO-MPO/04 - Strategic Salmon Data Policy and Analytics/07 - Data Products & Data/21 - Transitory Files/{GLOBAL_DATASET}/{GLOBAL_DATAFILE}\"\n",
    "    find_duplicates_and_percentage(\n",
    "        dataset_path=datafilepath\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Test failed!\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completeness (P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The threshold is for removing a column that meets the threshold of the percentage of blanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeness_test(dataset_path, exclude_columns=[], threshold=0.75):\n",
    "    dataset = read_data(dataset_path)\n",
    "\n",
    "    # Exclude the 'Comment' column if it exists in the dataset\n",
    "    if \"Comment\" in dataset.columns:\n",
    "        dataset = dataset.drop(columns=[\"Comment\"])\n",
    "\n",
    "    # Exclude columns in exclude_columns if they exist in the dataset\n",
    "    dataset = dataset.drop(\n",
    "        columns=[col for col in exclude_columns if col in dataset.columns]\n",
    "    )\n",
    "\n",
    "    # Calculate the percentage of non-null (non-missing) values in each column\n",
    "    is_null_percentage = dataset.isna().mean()\n",
    "\n",
    "    # Identify columns with non-null percentage less than or equal to the threshold\n",
    "    columns_to_keep = is_null_percentage[is_null_percentage <= threshold].index\n",
    "\n",
    "    # Keep columns that exceed the threshold of non-null values\n",
    "    dataset2 = dataset[columns_to_keep]\n",
    "\n",
    "    # Calculate the actual percentage of non-missing values in the dataset\n",
    "    total_non_missing = dataset2.notna().sum().sum()\n",
    "    total_obs = dataset2.shape[0] * dataset2.shape[1]\n",
    "    completeness_score = total_non_missing / total_obs\n",
    "\n",
    "    # log the results\n",
    "    log_score(\n",
    "        test_name=\"Completeness (P)\",\n",
    "        dataset_name=get_dataset_name(dataset_path),\n",
    "        selected_columns=None,\n",
    "        threshold=threshold,\n",
    "        score=completeness_score,\n",
    "    )\n",
    "\n",
    "    return completeness_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OnakD\\AppData\\Local\\Temp\\1\\ipykernel_14756\\3180660.py:5: DtypeWarning: Columns (27,28,29,30,31,32,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "# \"North and Central Coast NuSEDS_20241004.xlsx\"\n",
    "# \"West Coast Vancouver Island NuSEDS_20241004.xlsx\"\n",
    "# \"Yukon and Transboundary NuSEDS_20241004.xlsx\"\n",
    "try:\n",
    "    datafilepath = f\"C:/Users/{GLOBAL_USER}/OneDrive - DFO-MPO/04 - Strategic Salmon Data Policy and Analytics/07 - Data Products & Data/21 - Transitory Files/{GLOBAL_DATASET}/{GLOBAL_DATAFILE}\"\n",
    "    completeness_test(\n",
    "        datafilepath,\n",
    "        threshold=0.75,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"Test failed!\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeliness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def calc_timeliness(refresh_date, cycle_day):\n",
    "    refresh_date = pd.to_datetime(refresh_date)\n",
    "    unupdate_cycle = np.max([((datetime.now() - refresh_date).days / cycle_day) - 1, 0])\n",
    "\n",
    "    # unupdate_cycle = np.floor((datetime.now() - refresh_date).days/cycle_day)\n",
    "    # print((datetime.now() - refresh_date).days/cycle_day)\n",
    "    return np.max([0, 100 - (unupdate_cycle * (100 / 3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.39269406392694"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_timeliness(\"2022-12-01\", cycle_day=365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Reports\n",
    "Run all the functions above first before running this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that output reports can be generated through the data quality tests of\n",
    "<p>    - Consistency type 1\n",
    "<p>    - Accuracy type 2\n",
    "<p>    - Accuracy type 3\n",
    "<p>    - Completeness\n",
    "<p>          \n",
    "<p>  *Completeness test does not require an output report (just find the blanks in the dataset). The rest can be found below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency Type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_datasets(dataset_path, column_mapping, ref_dataset_path=None):\n",
    "    # Read the data file\n",
    "    df = read_data(dataset_path)\n",
    "\n",
    "    # Initialize ref_df if a ref dataset is provided\n",
    "    if ref_dataset_path:\n",
    "        df_ref = read_data(ref_dataset_path)\n",
    "        ref_data = True  # Flag to indicate we are using a ref dataset\n",
    "    else:\n",
    "        ref_data = False  # No ref dataset, compare within the same dataset\n",
    "\n",
    "    for selected_column, m_selected_column in column_mapping.items():\n",
    "        if ref_data:\n",
    "            # Compare to ref dataset\n",
    "            unique_observations = get_names_used_for_column(df_ref, m_selected_column)\n",
    "        else:\n",
    "            # Use own column for comparison\n",
    "            unique_observations = get_names_used_for_column(df, selected_column)\n",
    "\n",
    "        # Iterate over each row in the selected column\n",
    "        column_results = []\n",
    "        for value in df[selected_column]:\n",
    "            # Check if the value exists in unique_observations and append the result to column_results\n",
    "            if pd.isnull(value):\n",
    "                column_results.append(\n",
    "                    False\n",
    "                )  # or True, depending on how you want to handle NaN values\n",
    "            else:\n",
    "                column_results.append(value in unique_observations)\n",
    "\n",
    "        # Add the results as a new column in the DataFrame\n",
    "        df[selected_column + \"_comparison\"] = column_results\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/test/Salmonid_Enhancement_Program_Releases.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m column_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTOCK_CU_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCU_Display\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTOCK_CU_INDEX\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFULL_CU_IN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m }  \u001b[38;5;66;03m# the pattern for comparison is 'dataset column' : 'reference column'\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mcompare_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/test/Salmonid_Enhancement_Program_Releases.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mref_dataset_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/Pacific Salmon Population Unit Crosswalk_Final_20240513.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[144], line 3\u001b[0m, in \u001b[0;36mcompare_datasets\u001b[1;34m(dataset_path, column_mapping, ref_dataset_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare_datasets\u001b[39m(dataset_path, column_mapping, ref_dataset_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Read the data file\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mread_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Initialize ref_df if a ref dataset is provided\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ref_dataset_path:\n",
      "Cell \u001b[1;32mIn[127], line 9\u001b[0m, in \u001b[0;36mread_data\u001b[1;34m(dataset_path)\u001b[0m\n\u001b[0;32m      5\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[0;32m      6\u001b[0m         dataset_path, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcp1252\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m     )  \u001b[38;5;66;03m# sometimes if the function has issue reading a csv file, include: , encoding = 'cp1252')\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m file_extension \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 9\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported file type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/test/Salmonid_Enhancement_Program_Releases.xlsx'"
     ]
    }
   ],
   "source": [
    "column_mapping = {\n",
    "    \"STOCK_CU_NAME\": \"CU_Display\",\n",
    "    \"STOCK_CU_INDEX\": \"FULL_CU_IN\",\n",
    "}  # the pattern for comparison is 'dataset column' : 'reference column'\n",
    "compare_datasets(\n",
    "    dataset_path=\"data/test/Salmonid_Enhancement_Program_Releases.xlsx\",\n",
    "    column_mapping=column_mapping,\n",
    "    ref_dataset_path=\"data/Pacific Salmon Population Unit Crosswalk_Final_20240513.xlsx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 1: Using isdigit to find non-numerical entries\n",
    "def find_non_digits(s):\n",
    "    # Ensure the value is treated as a string\n",
    "    s = str(s)\n",
    "    return [char for char in s if not (char.isdigit() or char == \".\")]\n",
    "\n",
    "\n",
    "# Function 2 : Check if each row has only numbers in each selected column and add results as new columns\n",
    "def add_only_numbers_columns(dataset_path, selected_columns):\n",
    "    adf = read_data(dataset_path)\n",
    "    selected_columns = [col for col in adf.columns if col in selected_columns]\n",
    "\n",
    "    for column_name in selected_columns:\n",
    "        adf[column_name + \"_Only_Numbers\"] = adf[column_name].apply(\n",
    "            lambda x: len(find_non_digits(x)) == 0\n",
    "        )\n",
    "\n",
    "    return adf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_only_numbers_columns(\n",
    "    dataset_path=\"data/test/SEP Facilities.xlsx\", selected_columns=[\"LicNo\", \"FRN\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-11-28 16:53:40'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_name(dataset_path):\n",
    "    # Extract the file name from the path (e.g., 'Dataset_A.csv')\n",
    "    file_name = os.path.basename(dataset_path)\n",
    "    # Split the file name to remove the extension (e.g., 'Dataset_A')\n",
    "    dataset_name = os.path.splitext(file_name)[0]\n",
    "    return dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More up to date code for the score log can be found in the \"Setup\" section, the code here is treated more as a testing space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log a new row into the DQS_Log.xlsx file\n",
    "def log_score(test_name, dataset_name, score, threshold=None):\n",
    "    # Convert score to a percentage\n",
    "    percentage_score = score * 100\n",
    "\n",
    "    # Load the Excel file into a DataFrame\n",
    "    log_file = \"DQS_Log_Test.xlsx\"\n",
    "\n",
    "    # Set threshold to \"No threshold\" if it is not provided\n",
    "    if threshold is None:\n",
    "        threshold_value = \"no threshold\"\n",
    "    else:\n",
    "        threshold_value = threshold\n",
    "    # Try loading the existing Excel file\n",
    "    try:\n",
    "        df = read_data(log_file)\n",
    "    except FileNotFoundError:\n",
    "        # Create an empty DataFrame if file doesn't exist (shouldn't be the case if you already created it)\n",
    "        df = pd.DataFrame(\n",
    "            columns=[\"Dataset\", \"Test\", \"Threshold\", \"Date_Calculated\", \"Score\"]\n",
    "        )\n",
    "\n",
    "    # Prepare the new row as a DataFrame\n",
    "    new_row = pd.DataFrame(\n",
    "        {\n",
    "            \"Dataset\": [dataset_name],\n",
    "            \"Test\": [test_name],\n",
    "            \"Date_Calculated\": [datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")],\n",
    "            \"Threshold\": [threshold_value],\n",
    "            \"Score\": [percentage_score],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Append the new row to the DataFrame\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame back to the Excel file\n",
    "    df.to_excel(log_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the file to sharepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to copy the log file to another folder\n",
    "def copy_log_file(destination_folder):\n",
    "    # Define the name of the file and the current working directory\n",
    "    log_file = \"DQS_Log_Test.xlsx\"\n",
    "\n",
    "    # Get the current working directory (if needed)\n",
    "    current_directory = os.getcwd()\n",
    "\n",
    "    # Define the source path (current working directory + file)\n",
    "    source_path = os.path.join(current_directory, log_file)\n",
    "\n",
    "    # Define the destination path (destination folder + file)\n",
    "    destination_path = os.path.join(destination_folder, log_file)\n",
    "\n",
    "    # Copy the file to the destination folder\n",
    "    shutil.copy(source_path, destination_path)\n",
    "\n",
    "    print(f\"File copied to {destination_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this function when saving the excel document from the working directory to Sharepoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the destination folder where you want to copy the file\n",
    "destination_folder = \"C:/Users/EwertM/Documents/Portal/DataQuality\"\n",
    "\n",
    "copy_log_file(destination_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
