{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1 Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test whether there are symbols in numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 1: Using isdigit to find non-numerical entries\n",
    "def find_non_digits(s):\n",
    "    # Ensure the value is treated as a string\n",
    "    s = str(s)\n",
    "    return [char for char in s if not (char.isdigit() or char == \".\")]\n",
    "\n",
    "\n",
    "# Function 2 : Calculate the score\n",
    "def accuracy_score(dataset_path, selected_columns):\n",
    "    adf = read_data(dataset_path)\n",
    "\n",
    "    # Check if all specified columns were extracted, if not raise Key error\n",
    "    for column in selected_columns:\n",
    "        if column not in adf.columns:\n",
    "            raise KeyError(column)\n",
    "        \n",
    "    selected_columns = [col for col in adf.columns if col in selected_columns]\n",
    "\n",
    "    all_accuracy_scores = []\n",
    "\n",
    "    for column_name in selected_columns:\n",
    "        # Drop NA, null, or blank values from column\n",
    "        column_data = adf[column_name].dropna()\n",
    "\n",
    "        total_rows = len(column_data)\n",
    "\n",
    "        if total_rows > 0:  # to avoid division by zero\n",
    "            non_digit_chars_per_row = column_data.apply(find_non_digits)\n",
    "            non_numerical_count = non_digit_chars_per_row.apply(\n",
    "                lambda x: len(x) > 0\n",
    "            ).sum()\n",
    "            accuracy_score = (total_rows - non_numerical_count) / total_rows\n",
    "            all_accuracy_scores.append(accuracy_score)\n",
    "\n",
    "    overall_accuracy_score = (\n",
    "        sum(all_accuracy_scores) / len(all_accuracy_scores)\n",
    "        if all_accuracy_scores\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    # log the results\n",
    "    log_score(\n",
    "        test_name=\"Accuracy (A1)\",\n",
    "        dataset_name=get_dataset_name(dataset_path),\n",
    "        selected_columns=selected_columns,\n",
    "        threshold=None,\n",
    "        score=overall_accuracy_score,\n",
    "    )\n",
    "\n",
    "    return overall_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A2 Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_iqr(\n",
    "    dataset_path,\n",
    "    selected_columns,\n",
    "    groupby_column=None,\n",
    "    threshold=1.5,\n",
    "    minimum_score=0.85,\n",
    "):\n",
    "    df = read_data(dataset_path)\n",
    "\n",
    "    outliers_dict = {}\n",
    "\n",
    "    # Ensure selected columns are numeric  \n",
    "    for column in selected_columns:  \n",
    "        df[column] = df[column].astype(str).str.replace(r'[^\\d.-]', '', regex=True)  \n",
    "        df[column] = pd.to_numeric(df[column], errors='coerce')  \n",
    "\n",
    "    # If a groupby column is specified, perform the IQR calculation within each group\n",
    "    if groupby_column:\n",
    "        grouped = df.groupby(groupby_column)\n",
    "        for column in selected_columns:\n",
    "            # Apply the outlier detection for each group\n",
    "            outliers = grouped[column].apply(\n",
    "                lambda x: (\n",
    "                    (\n",
    "                        x\n",
    "                        < x.quantile(0.25)\n",
    "                        - threshold * (x.quantile(0.75) - x.quantile(0.25))\n",
    "                    )\n",
    "                    | (\n",
    "                        x\n",
    "                        > x.quantile(0.75)\n",
    "                        + threshold * (x.quantile(0.75) - x.quantile(0.25))\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            # Combine the outlier Series into a single Series that corresponds to the original DataFrame index\n",
    "            outliers_dict[column] = 1 - outliers.groupby(groupby_column).mean()\n",
    "    else:\n",
    "        # Perform the IQR calculation on the whole column if no groupby column is specified\n",
    "        for column in selected_columns:\n",
    "            Q1 = df[column].quantile(0.25)\n",
    "            Q3 = df[column].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - threshold * IQR\n",
    "            upper_bound = Q3 + threshold * IQR\n",
    "            outliers = (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "            outliers_dict[column] = 1 - outliers.mean()\n",
    "\n",
    "    #compute final score\n",
    "    total_groups = len(outliers_dict)\n",
    "    groups_above = sum(1 for score in outliers_dict.values() if score > minimum_score)\n",
    "    final_score = groups_above / total_groups if total_groups > 0 else 0\n",
    "\n",
    "    #final_score = {}\n",
    "\n",
    "    # for key in outliers_dict.keys():\n",
    "    #     print(outliers_dict[key])\n",
    "    #     arr = outliers_dict[key].values\n",
    "    #     value_out = np.sum(arr > minimum_score) / len(arr)\n",
    "    #     final_score[key] = value_out\n",
    "    \n",
    "    # for key, value in outliers_dict.items():  \n",
    "    #     print(key, value)\n",
    "    #     # Check if the proportion of non-outliers is greater than the minimum score  \n",
    "    #     value_out = value > minimum_score  \n",
    "    #     # Store the result (True or False) in the final_score dictionary  \n",
    "    #     final_score[key] = value_out  \n",
    "\n",
    "    # log the results\n",
    "\n",
    "    log_score(\n",
    "        test_name=\"Accuracy (A2)\",\n",
    "        dataset_name=get_dataset_name(dataset_path),\n",
    "        selected_columns=selected_columns,\n",
    "        threshold=threshold,\n",
    "        score=final_score,\n",
    "    )\n",
    "\n",
    "    return outliers_dict, final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3 Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 1: finding duplicates\n",
    "def find_duplicates_and_percentage(dataset_path):\n",
    "\n",
    "    df = read_data(dataset_path)\n",
    "\n",
    "    # Find duplicate rows\n",
    "    duplicate_rows = df[df.duplicated(keep=False)]\n",
    "\n",
    "    # Calculate percentage of duplicate rows\n",
    "    total_rows = len(df)\n",
    "    total_duplicate_rows = len(duplicate_rows)\n",
    "    percentage_duplicate = 1 - (total_duplicate_rows / total_rows)\n",
    "\n",
    "    # Print duplicate rows\n",
    "    print(\"Duplicate Rows:\")\n",
    "    print(duplicate_rows)\n",
    "\n",
    "    # log the results\n",
    "    log_score(\n",
    "        test_name=\"Accuracy (A3)\",\n",
    "        dataset_name=get_dataset_name(dataset_path),\n",
    "        selected_columns=None,\n",
    "        threshold=None,\n",
    "        score=percentage_duplicate,\n",
    "    )\n",
    "\n",
    "    # Print percentage of duplicate rows\n",
    "    print(f\"\\nDuplication Score: {percentage_duplicate*100}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
