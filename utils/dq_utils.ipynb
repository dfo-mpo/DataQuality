{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Util Functions for Set Up\n",
    "All cells must be run in main notebook for Data Quality Tests to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to read either csv or xlsx data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 0: Reading the dataset file\n",
    "def read_data(dataset_path):\n",
    "    _, file_extension = os.path.splitext(dataset_path)\n",
    "    if file_extension == \".csv\":\n",
    "        try:  \n",
    "            df = pd.read_csv(dataset_path, encoding=\"utf-8-sig\")  \n",
    "        except UnicodeDecodeError:  \n",
    "            df = pd.read_csv(dataset_path, encoding=\"cp1252\") \n",
    "    elif file_extension == \".xlsx\":\n",
    "        df = pd.read_excel(dataset_path)\n",
    "    else:\n",
    "        print(\"Unsupported file type\")\n",
    "        df = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to log the scores into an xlsx file (already created, existing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to log a new row into the DQS_Log_XX.xlsx file\n",
    "def log_score(test_name, dataset_name, score, selected_columns, threshold=None):\n",
    "    # Convert score to a percentage\n",
    "    percentage_score = score\n",
    "\n",
    "    # Load the Excel file into a DataFrame\n",
    "    log_file = \"DQS_Log_Beta.xlsx\"\n",
    "\n",
    "    # Set threshold to \"No threshold\" if it is not provided\n",
    "    if threshold is None:\n",
    "        threshold_value = \"no threshold\"\n",
    "    else:\n",
    "        threshold_value = threshold\n",
    "\n",
    "    # If selected_columns is None, assume \"All\" was tested\n",
    "    if selected_columns is None:\n",
    "        columns_tested = \"All columns\"\n",
    "    else:\n",
    "        # Convert selected_columns list to a string if specific columns are provided\n",
    "        columns_tested = \", \".join(selected_columns)\n",
    "\n",
    "    # Try loading the existing Excel file\n",
    "    try:\n",
    "        df = read_data(log_file)\n",
    "    except FileNotFoundError:\n",
    "        # Create an empty DataFrame if file doesn't exist (shouldn't be the case if you already created it)\n",
    "        df = pd.DataFrame(\n",
    "            columns=[\"Dataset\", \"Test\", \"Threshold\", \"Date_Calculated\", \"Score\"]\n",
    "        )\n",
    "\n",
    "    # Prepare the new row as a DataFrame\n",
    "    new_row = pd.DataFrame(\n",
    "        {\n",
    "            \"Dataset\": [dataset_name],\n",
    "            \"Columns_Tested\": [columns_tested],  # Add the list of columns tested\n",
    "            \"Test\": [test_name],\n",
    "            \"Date_Calculated\": [datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")],\n",
    "            \"Threshold\": [threshold_value],\n",
    "            \"Score\": [percentage_score],\n",
    "            \"User\": GLOBAL_USER\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Append the new row to the DataFrame\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame back to the Excel file\n",
    "    df.to_excel(log_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to extract dataset name from a path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_name(dataset_path):\n",
    "    # Extract the file name from the path (e.g., 'Dataset_A.csv')\n",
    "    file_name = os.path.basename(dataset_path)\n",
    "    # Split the file name to remove the extension (e.g., 'Dataset_A')\n",
    "    dataset_name = os.path.splitext(file_name)[0]\n",
    "    return dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define colour variables for console outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSI escape code for red text  \n",
    "RED = \"\\033[31m\"  \n",
    "RESET = \"\\033[0m\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completeness Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeness_test(dataset_path, exclude_columns=[], threshold=0.75):\n",
    "    dataset = read_data(dataset_path)\n",
    "\n",
    "    # Exclude the 'Comment' column if it exists in the dataset\n",
    "    if \"Comment\" in dataset.columns:\n",
    "        dataset = dataset.drop(columns=[\"Comment\"])\n",
    "\n",
    "    # Exclude columns in exclude_columns if they exist in the dataset\n",
    "    dataset = dataset.drop(\n",
    "        columns=[col for col in exclude_columns if col in dataset.columns]\n",
    "    )\n",
    "\n",
    "    # Calculate the percentage of non-null (non-missing) values in each column\n",
    "    is_null_percentage = dataset.isna().mean()\n",
    "\n",
    "    # Identify columns with non-null percentage less than or equal to the threshold\n",
    "    columns_to_keep = is_null_percentage[is_null_percentage <= threshold].index\n",
    "\n",
    "    # Keep columns that exceed the threshold of non-null values\n",
    "    dataset2 = dataset[columns_to_keep]\n",
    "\n",
    "    # Calculate the actual percentage of non-missing values in the dataset\n",
    "    total_non_missing = dataset2.notna().sum().sum()\n",
    "    total_obs = dataset2.shape[0] * dataset2.shape[1]\n",
    "    completeness_score = total_non_missing / total_obs\n",
    "\n",
    "    # log the results\n",
    "    log_score(\n",
    "        test_name=\"Completeness (P)\",\n",
    "        dataset_name=get_dataset_name(dataset_path),\n",
    "        selected_columns=None,\n",
    "        threshold=threshold,\n",
    "        score=completeness_score,\n",
    "    )\n",
    "\n",
    "    return completeness_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consistency Type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_datasets(dataset_path, column_mapping, ref_dataset_path=None):\n",
    "    # Read the data file\n",
    "    df = read_data(dataset_path)\n",
    "\n",
    "    # Initialize ref_df if a ref dataset is provided\n",
    "    if ref_dataset_path:\n",
    "        df_ref = read_data(ref_dataset_path)\n",
    "        ref_data = True  # Flag to indicate we are using a ref dataset\n",
    "    else:\n",
    "        ref_data = False  # No ref dataset, compare within the same dataset\n",
    "\n",
    "    for selected_column, m_selected_column in column_mapping.items():\n",
    "        if ref_data:\n",
    "            # Compare to ref dataset\n",
    "            unique_observations = get_names_used_for_column(df_ref, m_selected_column)\n",
    "        else:\n",
    "            # Use own column for comparison\n",
    "            unique_observations = get_names_used_for_column(df, selected_column)\n",
    "\n",
    "        # Iterate over each row in the selected column\n",
    "        column_results = []\n",
    "        for value in df[selected_column]:\n",
    "            # Check if the value exists in unique_observations and append the result to column_results\n",
    "            if pd.isnull(value):\n",
    "                column_results.append(\n",
    "                    False\n",
    "                )  # or True, depending on how you want to handle NaN values\n",
    "            else:\n",
    "                column_results.append(value in unique_observations)\n",
    "\n",
    "        # Add the results as a new column in the DataFrame\n",
    "        df[selected_column + \"_comparison\"] = column_results\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 1: Using isdigit to find non-numerical entries\n",
    "def find_non_digits(s):\n",
    "    # Ensure the value is treated as a string\n",
    "    s = str(s)\n",
    "    return [char for char in s if not (char.isdigit() or char == \".\")]\n",
    "\n",
    "\n",
    "# Function 2 : Check if each row has only numbers in each selected column and add results as new columns\n",
    "def add_only_numbers_columns(dataset_path, selected_columns):\n",
    "    adf = read_data(dataset_path)\n",
    "    selected_columns = [col for col in adf.columns if col in selected_columns]\n",
    "\n",
    "    for column_name in selected_columns:\n",
    "        adf[column_name + \"_Only_Numbers\"] = adf[column_name].apply(\n",
    "            lambda x: len(find_non_digits(x)) == 0\n",
    "        )\n",
    "\n",
    "    return adf"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
