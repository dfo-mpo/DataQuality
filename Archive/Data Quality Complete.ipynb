{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run everything in the set up, and double check the working directory so that the data can be read from that same directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os \n",
    "import re\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to set to the correct working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\luos\\\\OneDrive - DFO-MPO\\\\Python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change working directory to the same place where you saved the test datasets\n",
    "#os.chdir('C:/Users/luos/OneDrive - DFO-MPO/Python') #change directory\n",
    "os.getcwd() #check where the directory is (and whether the change was successful or not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to read either csv or xlsx data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 0: Reading the dataset file\n",
    "def read_data(dataset_path):  \n",
    "    _, file_extension = os.path.splitext(dataset_path)\n",
    "    if file_extension == '.csv':  \n",
    "        df = pd.read_csv(dataset_path)    \n",
    "    elif file_extension == '.xlsx':\n",
    "        df = pd.read_excel(dataset_path)  \n",
    "    else:\n",
    "        print('Unsupported file type')  \n",
    "        df = None  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consistency Type 1 (C1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate consistency score of a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is best run on CSV data where the column names are in the first row. It can also accept files that are in xlsx formats but it will only take data from the first sheet if there are more than one sheet in the excel file.\n",
    "\n",
    "Limitations: It will not check for differences in capitalization of the same word (since all the words will be changed to lower case before the similarity score is calculated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consistency Type 1 (C1) function\n",
    "\n",
    "# Dictionary mapping Canadian province abbreviations to their full names\n",
    "province_abbreviations = {\n",
    "    'BC': 'British Columbia',\n",
    "    'ON': 'Ontario',\n",
    "    'QC': 'Quebec',\n",
    "    'AB': 'Alberta',\n",
    "    'MB': 'Manitoba',\n",
    "    'SK': 'Saskatchewan',\n",
    "    'NS': 'Nova Scotia',\n",
    "    'NB': 'New Brunswick',\n",
    "    'NL': 'Newfoundland and Labrador',\n",
    "    'PE': 'Prince Edward Island',\n",
    "    'NT': 'Northwest Territories',\n",
    "    'YT': 'Yukon',\n",
    "    'NU': 'Nunavut'\n",
    "}\n",
    "\n",
    "def normalize_text(text, remove_numbers=False):\n",
    "    \"\"\"\n",
    "    Normalize input text by converting to lowercase, stripping whitespace,\n",
    "    replacing province abbreviations with full names, and removing non-alphanumeric characters.\n",
    "    Optionally remove numbers based on the flag.\n",
    "    \"\"\"\n",
    "    text = str(text).lower().strip()\n",
    "    for abbr, full in province_abbreviations.items():\n",
    "        text = re.sub(r'\\b' + abbr.lower() + r'\\b', full.lower(), text)\n",
    "    if remove_numbers:\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "    text = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
    "    return ' '.join(text.split())\n",
    "\n",
    "def extract_numbers(text):\n",
    "    \"\"\"\n",
    "    Extract all numbers from the input text and return them as a list of strings.\n",
    "    \"\"\"\n",
    "    return re.findall(r'\\d+', text)\n",
    "\n",
    "def remove_short_numbers(text):\n",
    "    \"\"\"\n",
    "    Remove numbers with 1 or 2 digits from the input text.\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\b\\d{1,4}\\b', '', text)\n",
    "\n",
    "def numeric_similarity(num1_list, num2_list):\n",
    "    \"\"\"\n",
    "    Calculate the similarity between two lists of numbers by comparing each digit.\n",
    "    Return the proportion of matching digits.\n",
    "    \"\"\"\n",
    "    num1, num2 = ' '.join(num1_list), ' '.join(num2_list)\n",
    "    matches = sum(1 for a, b in zip(num1, num2) if a == b)\n",
    "    max_length = max(len(num1), len(num2))\n",
    "    return matches / max_length if max_length > 0 else 0\n",
    "\n",
    "def string_similarity(str1, str2):\n",
    "    \"\"\"\n",
    "    Calculate the similarity between two strings using the SequenceMatcher from difflib.\n",
    "    Return the similarity ratio.\n",
    "    \"\"\"\n",
    "    return SequenceMatcher(None, str1, str2).ratio()\n",
    "\n",
    "def calculate_cosine_similarity(text_list, ref_list, Stop_Words):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between lists of texts using TF-IDF vectorization.\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words=Stop_Words, analyzer='word', ngram_range=(1, 2))\n",
    "    ref_vec = vectorizer.fit_transform(ref_list)\n",
    "    text_vec = vectorizer.transform(text_list)\n",
    "    return cosine_similarity(text_vec, ref_vec)\n",
    "\n",
    "def contains_short_number(num_list):\n",
    "    \"\"\"\n",
    "    Check if any number in the list has 1 or 2 digits.\n",
    "    \"\"\"\n",
    "    return any(len(num) <= 4 for num in num_list)\n",
    "\n",
    "def numbers_match(num_list1, num_list2):\n",
    "    \"\"\"\n",
    "    Check if any number in the first list is present in the second list.\n",
    "    \"\"\"\n",
    "    return any(num in num_list2 for num in num_list1)\n",
    "\n",
    "def calculate_combined_similarity(df, unique_observations, text_similarity_matrix):\n",
    "    \"\"\"\n",
    "    Combine text and numeric similarities into a single similarity matrix.\n",
    "    \"\"\"\n",
    "    # Make a copy of the text similarity matrix to modify it\n",
    "    combined_sim_matrix = np.copy(text_similarity_matrix)\n",
    "    \n",
    "    # Extract numeric parts from each unique observation\n",
    "    numeric_parts = [extract_numbers(obs) for obs in unique_observations]\n",
    "    \n",
    "    # Iterate over each pair of unique observations to calculate numeric similarity\n",
    "    for i, num_i in enumerate(numeric_parts):\n",
    "        for j, num_j in enumerate(numeric_parts):\n",
    "            if i != j:\n",
    "                # Calculate the numeric similarity for the current pair\n",
    "                num_sim = numeric_similarity(num_i, num_j)\n",
    "                \n",
    "                # Update the combined similarity matrix with the maximum value between text and numeric similarity\n",
    "                combined_sim_matrix[i, j] = max(combined_sim_matrix[i, j], num_sim)\n",
    "    \n",
    "    # Iterate over each pair of unique observations to calculate string similarity\n",
    "    for i, obs_i in enumerate(unique_observations):\n",
    "        for j, obs_j in enumerate(unique_observations):\n",
    "            if i != j:\n",
    "                # Calculate the string similarity for the current pair\n",
    "                seq_sim = string_similarity(obs_i, obs_j)\n",
    "                \n",
    "                # Update the combined similarity matrix with the maximum value between existing and sequence matcher \n",
    "                combined_sim_matrix[i, j] = max(combined_sim_matrix[i, j], seq_sim)\n",
    "    \n",
    "    return combined_sim_matrix\n",
    "\n",
    "def average_consistency_score(cosine_sim_matrix, threshold):\n",
    "    \"\"\"\n",
    "    Calculate the average consistency score based on the cosine similarity matrix and a given threshold.\n",
    "    \"\"\"\n",
    "    num_rows, num_columns = cosine_sim_matrix.shape\n",
    "    inconsistency = 0\n",
    "\n",
    "    for i in range(num_rows):\n",
    "        if np.any((cosine_sim_matrix[i] > threshold) & (cosine_sim_matrix[i] <= 1.0000000)):\n",
    "            inconsistency += 1\n",
    "    \n",
    "    return (num_rows - inconsistency) / num_rows\n",
    "\n",
    "def process_and_calculate_similarity(dataset_path, column_names, threshold, Stop_Words=['the', 'and']):\n",
    "    \"\"\"\n",
    "    Process the dataset, normalize the text, and calculate the similarity scores for multiple columns.\n",
    "    \"\"\"\n",
    "    # Read the dataset from the provided Excel file path\n",
    "    df = read_data(dataset_path)\n",
    "    overall_consistency_scores = []\n",
    "\n",
    "    # Iterate over each specified column\n",
    "    for column_name in column_names:\n",
    "        # Normalize the text in the specified column and store the results in a new column\n",
    "        df[f'Normalized {column_name}'] = df[column_name].apply(normalize_text)\n",
    "        \n",
    "        # Get unique normalized observations by removing duplicates and NaN values\n",
    "        unique_observations = pd.unique(df[f'Normalized {column_name}'].dropna().values.ravel())\n",
    "        \n",
    "        # Calculate the cosine similarity matrix for the unique normalized observations\n",
    "        text_sim_matrix = calculate_cosine_similarity(unique_observations.tolist(), unique_observations.tolist(), Stop_Words)\n",
    "        \n",
    "        # Set the diagonal of the similarity matrix to 0 to ignore self-similarity\n",
    "        np.fill_diagonal(text_sim_matrix, 0)\n",
    "        \n",
    "        # Combine text similarity with numeric similarity to get a final similarity matrix\n",
    "        combined_sim_matrix = calculate_combined_similarity(df, unique_observations, text_sim_matrix)\n",
    "        \n",
    "        # Initialize columns in the dataframe to store the recommended organization matches and all matches\n",
    "        df[f'Recommended {column_name}'] = None\n",
    "        df[f'All Matches {column_name}'] = None\n",
    "\n",
    "        # Iterate over each normalized organization in the dataframe\n",
    "        for i, norm_org in enumerate(df[f'Normalized {column_name}']):\n",
    "            # Find the index of the current normalized organization in the unique observations\n",
    "            try:\n",
    "                current_index = np.where(unique_observations == norm_org)[0][0]\n",
    "            except IndexError:\n",
    "                df.at[i, f'Recommended {column_name}'] = \"No significant match\"\n",
    "                df.at[i, f'All Matches {column_name}'] = []\n",
    "                continue\n",
    "            \n",
    "            # Get the similarities for the current organization from the combined similarity matrix\n",
    "            similarities = combined_sim_matrix[current_index]\n",
    "            \n",
    "            # Find the indices and values of all matching organizations\n",
    "            matched_indices = np.where(similarities >= threshold)[0]\n",
    "            all_matches = [unique_observations[idx] for idx in matched_indices]\n",
    "            all_match_scores = [similarities[idx] for idx in matched_indices]\n",
    "\n",
    "            best_score = 0\n",
    "            best_match = \"No significant match\"\n",
    "\n",
    "            # Extract numbers from the current organization\n",
    "            num_list_current = extract_numbers(norm_org)\n",
    "\n",
    "            for idx in matched_indices:\n",
    "                candidate_match = unique_observations[idx]\n",
    "                num_list_candidate = extract_numbers(candidate_match)\n",
    "\n",
    "                if contains_short_number(num_list_current) or contains_short_number(num_list_candidate):\n",
    "                    # If short numbers are present, ensure they match; otherwise, skip this match\n",
    "                    if not numbers_match(num_list_current, num_list_candidate):\n",
    "                        continue\n",
    "                    # Recalculate similarity excluding short numbers\n",
    "                    norm_org_no_nums = remove_short_numbers(norm_org)\n",
    "                    candidate_no_nums = remove_short_numbers(candidate_match)\n",
    "                    recalculated_similarity = string_similarity(norm_org_no_nums, candidate_no_nums)\n",
    "                    if recalculated_similarity > best_score:\n",
    "                        best_score = recalculated_similarity\n",
    "                        best_match = candidate_match\n",
    "                else:\n",
    "                    if similarities[idx] > best_score:\n",
    "                        best_score = similarities[idx]\n",
    "                        best_match = candidate_match\n",
    "\n",
    "            # Assign the best match to the dataframe\n",
    "            if best_score > threshold:\n",
    "                df.at[i, f'Recommended {column_name}'] = f\"{best_match} ({best_score:.2f})\"\n",
    "            else:\n",
    "                df.at[i, f'Recommended {column_name}'] = \"No significant match\"\n",
    "\n",
    "            # Store all matches\n",
    "            df.at[i, f'All Matches {column_name}'] = ', '.join([f\"{match} ({score:.2f})\" for match, score in zip(all_matches, all_match_scores) if score > threshold])\n",
    "\n",
    "        # Calculate the overall consistency score for the current column\n",
    "        consistency_score = average_consistency_score(text_sim_matrix, threshold)\n",
    "        overall_consistency_scores.append(consistency_score)\n",
    "\n",
    "    # Calculate the overall consistency score as the average of individual consistency scores\n",
    "    overall_consistency_score = np.mean(overall_consistency_scores)\n",
    "    df['Overall Consistency Score'] = overall_consistency_score\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Consistency Calculations\n",
    "processed_df = process_and_calculate_similarity(\n",
    "    dataset_path='data/restoration projects_dataportal.csv', # Define clear path for the data file with quotes\n",
    "    column_names = ['Project Name'], \n",
    "    threshold = 0.91)\n",
    "\n",
    "processed_df['Overall Consistency Score'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Habitat Restoration Data for the Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = process_and_calculate_similarity(\n",
    "    dataset_path = 'data/test/SalmonHabitatRestorationProjects_DataPortal_June_FinalFields_20240613.csv', # Define clear path for the data file with quotes\n",
    "    column_names=['project_name'], \n",
    "    threshold = 0.91, \n",
    "    Stop_Words = ['']\n",
    "    )  \n",
    "\n",
    "processed_df['Overall Consistency Score'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Salmonid Enhancement Program Post-Season Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9883483483483484"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = process_and_calculate_similarity(\n",
    "    dataset_path = 'data/test/Salmonid_Enhancement_Program_Releases.xlsx', # Define clear path for the data file with quotes\n",
    "    column_names=['PROJ_NAME', 'FACILITY_NAME'], \n",
    "    threshold = 0.91, \n",
    "    Stop_Words = ['']\n",
    "    )  \n",
    "\n",
    "processed_df['Overall Consistency Score'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9901664467242773"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = process_and_calculate_similarity(\n",
    "    dataset_path = 'data/test/Hatchery Releases EPDA Data - NOT FINAL.xlsx', # Define clear path for the data file with quotes\n",
    "    column_names=['PROJ_NAME', 'FACILITY_NAME'], \n",
    "    threshold = 0.91, \n",
    "    Stop_Words = ['']\n",
    "    )  \n",
    "\n",
    "processed_df['Overall Consistency Score'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9556493049921575"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_consistency_score = process_and_calculate_similarity(\n",
    "    dataset_path = 'data/Pacific Salmon Population Unit Crosswalk_Final_20240513.xlsx', # Define clear path for the data file with quotes\n",
    "    selected_columns=['STOCK_POP_NAME'], \n",
    "    threshold = 0.91, \n",
    "    Stop_Words = ['']\n",
    "    )  \n",
    "\n",
    "avg_consistency_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consistency Type 2 (C2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate consistency score of datasets with a reference list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The compared columns in question must be identical to the ref list, otherwise they will be penalized more harshly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 1: Get names used for a single column  \n",
    "def get_names_used_for_column(df, column_name):  \n",
    "    unique_observations = pd.unique(df[column_name].dropna().values.ravel())  \n",
    "    return unique_observations  \n",
    "\n",
    "# Function 2: Calculate Cosine Similarity  \n",
    "def calculate_cosine_similarity(text_list, ref_list, Stop_Words):  \n",
    "    count_vectorizer = CountVectorizer(stop_words= Stop_Words)  \n",
    "    ref_vec = count_vectorizer.fit_transform(ref_list).todense()  \n",
    "    ref_vec_array = np.array(ref_vec) \n",
    "    text_vec = count_vectorizer.transform(text_list).todense()  \n",
    "    text_vec_array = np.array(text_vec) \n",
    "    cosine_sim = np.round((cosine_similarity(text_vec_array, ref_vec_array)), 2)  \n",
    "    return cosine_sim  \n",
    "\n",
    "# Function 3: Average Consistency Score  \n",
    "def average_consistency_score(cosine_sim_df, threshold=0.91):\n",
    "    num_rows, num_columns = cosine_sim_df.shape\n",
    "    total_count = 0  # This will count all values above or equal to the threshold  \n",
    "    \n",
    "    for i in range(num_rows):\n",
    "        if np.max(cosine_sim_df[i]) >= threshold: #Include all comparisons \n",
    "            total_count += 1\n",
    "    total_observations = num_rows  # Total number of observations  \n",
    "    average_consistency_score = total_count / total_observations  \n",
    "    return average_consistency_score \n",
    "   \n",
    "def process_and_calculate_similarity_ref(dataset_path, column_mapping, ref_dataset_path = None, threshold = 0.91, Stop_Words = 'activity'):    \n",
    "    #Read the data file  \n",
    "    df = read_data(dataset_path)  \n",
    "  \n",
    "    # Initialize ref_df if a ref dataset is provided  \n",
    "    if ref_dataset_path:  \n",
    "        df_ref = read_data(ref_dataset_path)  \n",
    "        ref_data = True #Flag to indicate we are using a ref dataset  \n",
    "    else:  \n",
    "        ref_data = False #No ref dataset, compare within the same dataset  \n",
    "  \n",
    "    all_consistency_scores = []    \n",
    "      \n",
    "    for selected_column, m_selected_column in column_mapping.items():    \n",
    "        if ref_data:  \n",
    "             # Compare to ref dataset    \n",
    "            unique_observations = get_names_used_for_column(df_ref, m_selected_column)    \n",
    "        else:    \n",
    "            # Use own column for comparison    \n",
    "            unique_observations = get_names_used_for_column(df, selected_column)  \n",
    "              \n",
    "        cosine_sim_matrix = calculate_cosine_similarity(df[selected_column].dropna(), unique_observations, Stop_Words=Stop_Words)    \n",
    "        column_consistency_score = average_consistency_score(cosine_sim_matrix, threshold)    \n",
    "        all_consistency_scores.append(column_consistency_score)    \n",
    "  \n",
    "    # Calculate the average of all consistency scores    \n",
    "    overall_avg_consistency = sum(all_consistency_scores) / len(all_consistency_scores) if all_consistency_scores else None    \n",
    "  \n",
    "    return overall_avg_consistency "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993045537439778"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_mapping = {'STOCK_CU_NAME':'CU_Display', 'STOCK_CU_INDEX':'FULL_CU_IN'}  #the pattern for comparison is 'dataset column' : 'reference column'\n",
    "process_and_calculate_similarity_ref(\n",
    "    dataset_path='data/test/2024-03-28 1_qryThermal_NatEmerg.xlsx', \n",
    "    column_mapping=column_mapping, \n",
    "    ref_dataset_path = 'data/Pacific Salmon Population Unit Crosswalk_Final_20240513.xlsx',\n",
    "    threshold = 1, \n",
    "    Stop_Words = [''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Habitat Restoration Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9924551386623165"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_mapping = {'CU_Name':'CU_Display', 'FULL_CU_IN':'FULL_CU_IN','SMU_Display':'SMU_Display', 'SMU_ID':'SMU_ID'}  #the pattern for comparison is 'dataset column' : 'reference column'\n",
    "process_and_calculate_similarity_ref(\n",
    "    dataset_path='data/test/SalmonHabitatRestorationProjects_DataPortal_June_FinalFields_20240613.csv', \n",
    "    column_mapping=column_mapping, \n",
    "    ref_dataset_path = 'data/Pacific Salmon Population Unit Crosswalk_Final_20240513.xlsx',\n",
    "    threshold = 1,\n",
    "    Stop_Words = [''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Salmonid Enhancement Program Post-Season Reports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9930453481408895"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_mapping = {'STOCK_CU_NAME':'CU_Display', 'STOCK_CU_INDEX':'FULL_CU_IN'}  #the pattern for comparison is 'dataset column' : 'reference column'\n",
    "process_and_calculate_similarity_ref(\n",
    "    dataset_path='data/test/Salmonid_Enhancement_Program_Releases.xlsx', \n",
    "    column_mapping=column_mapping, \n",
    "    ref_dataset_path = 'data/Pacific Salmon Population Unit Crosswalk_Final_20240513.xlsx',\n",
    "    threshold = 1,\n",
    "    Stop_Words = [''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pacific Salmon Outlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_mapping = {'SMU NAME':'SMU_Display', 'CU NAME':'CU_Display', 'FULL CU INDEX':'FULL_CU_IN'}  #the pattern for comparison is 'dataset column' : 'reference column'\n",
    "process_and_calculate_similarity_ref(\n",
    "    dataset_path='data/test/salmonoutlook_dataportal_DRAFT_PLACEHOLDER.xlsx', \n",
    "    column_mapping=column_mapping, \n",
    "    ref_dataset_path = 'data/Pacific Salmon Population Unit Crosswalk_Final_20240513.xlsx',\n",
    "    threshold = 1,\n",
    "    Stop_Words = [''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Type 1 (A1, Mixed Data Types, Symbols in Numerics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 1: Using isdigit to find non-numerical entries\n",
    "def find_non_digits(s):  \n",
    "    # Ensure the value is treated as a string  \n",
    "    s = str(s)  \n",
    "    return [char for char in s if not (char.isdigit() or char == '.')]  \n",
    "\n",
    "# Function 2 : Calculate the score\n",
    "def accuracy_score(dataset_path, selected_columns):\n",
    "    adf = read_data(dataset_path)\n",
    "    selected_columns = [col for col in adf.columns if col in selected_columns] \n",
    "\n",
    "    all_accuracy_scores = []\n",
    "    \n",
    "    for column_name in selected_columns:  \n",
    "        # Drop NA, null, or blank values from column  \n",
    "        column_data = adf[column_name].dropna()  \n",
    "          \n",
    "        total_rows = len(column_data)  \n",
    "          \n",
    "        if total_rows > 0:  # to avoid division by zero  \n",
    "            non_digit_chars_per_row = column_data.apply(find_non_digits)  \n",
    "            non_numerical_count = non_digit_chars_per_row.apply(lambda x: len(x) > 0).sum()   \n",
    "            accuracy_score = (total_rows - non_numerical_count) / total_rows  \n",
    "            all_accuracy_scores.append(accuracy_score)    \n",
    "  \n",
    "    overall_accuracy_score = sum(all_accuracy_scores) / len(all_accuracy_scores) if all_accuracy_scores else None   \n",
    "\n",
    "    return overall_accuracy_score  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9639175257731958"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    dataset_path = 'data/test/SEP Facilities.xlsx',\n",
    "    selected_columns = ['LicNo', 'FRN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Salmonoid Enhancement Program (SEP) Post-Season Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(\n",
    "    dataset_path = 'data/test/Salmonid_Enhancement_Program_Releases.xlsx',\n",
    "    selected_columns = ['AVE_WEIGHT','AVE_LENGTH', 'TotalRelease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1  =read_data('data/test/Hatchery Releases EPDA Data - NOT FINAL.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "is_numeric_dtype(test1['AVE_LENGTH'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Type 2 (A2 Outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_iqr(dataset_path, selected_columns, groupby_column = None, threshold = 1.5, minimum_score= 0.85):  \n",
    "    df = read_data(dataset_path)\n",
    "    outliers_dict = {}\n",
    "\n",
    "   # If a groupby column is specified, perform the IQR calculation within each group  \n",
    "    if groupby_column:  \n",
    "        grouped = df.groupby(groupby_column)  \n",
    "        for column in selected_columns:  \n",
    "            # Apply the outlier detection for each group  \n",
    "            outliers = grouped[column].apply(lambda x: ((x < x.quantile(0.25) - threshold * (x.quantile(0.75) - x.quantile(0.25))) |  \n",
    "                                                        (x > x.quantile(0.75) + threshold * (x.quantile(0.75) - x.quantile(0.25))))) \n",
    "            # Combine the outlier Series into a single Series that corresponds to the original DataFrame index  \n",
    "            outliers_dict[column] = (1 - outliers.groupby(groupby_column).mean())\n",
    "    else:  \n",
    "        # Perform the IQR calculation on the whole column if no groupby column is specified  \n",
    "        for column in selected_columns:  \n",
    "            Q1 = df[column].quantile(0.25)  \n",
    "            Q3 = df[column].quantile(0.75)  \n",
    "            IQR = Q3 - Q1  \n",
    "  \n",
    "            lower_bound = Q1 - threshold * IQR  \n",
    "            upper_bound = Q3 + threshold * IQR  \n",
    "  \n",
    "            outliers = (df[column] < lower_bound) | (df[column] > upper_bound)  \n",
    "            outliers_dict[column] = (1 - outliers.mean())\n",
    "    \n",
    "    # compute final score  \n",
    "    #total_groups = len(outliers_dict)  \n",
    "    #groups_above = sum(1 for score in outliers_dict.values() if score > minimum_score)  \n",
    "    #final_score = groups_above / total_groups if total_groups > 0 else 0  \n",
    "    \n",
    "    final_score = {}\n",
    "    \n",
    "    for key in outliers_dict.keys():\n",
    "        arr = outliers_dict[key].values\n",
    "        value_out = np.sum(arr > minimum_score)/len(arr)\n",
    "        final_score[key] = value_out\n",
    "  \n",
    "    return outliers_dict, final_score        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Escapement_Total': Species\n",
       "  Chinook    0.929138\n",
       "  Chum       0.935484\n",
       "  Coho       0.879154\n",
       "  Pink       0.966667\n",
       "  Sockeye    0.892490\n",
       "  Name: Escapement_Total, dtype: float64},\n",
       " {'Escapement_Total': 1.0})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_outliers_iqr(\n",
    "    dataset_path='data/test/new Escapement Data 2022.xlsx',\n",
    "    selected_columns=['Escapement_Total'],\n",
    "    groupby_column='Species',\n",
    "    threshold=1.5,\n",
    "    minimum_score= 0.85\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Escapement_Total': SMU\n",
       "  ALSEK CHINOOK SALMON                           0.978723\n",
       "  ALSEK SOCKEYE SALMON                           1.000000\n",
       "  ECVI/MAINLAND PINK SALMON                      0.800000\n",
       "  FRASER CHUM SALMON                             0.952381\n",
       "  FRASER FALL RUN 41 CHINOOK SALMON              0.985714\n",
       "  FRASER PINK SALMON - ODD                       0.971429\n",
       "  FRASER SOCKEYE SALMON - EARLY SUMMER           0.886301\n",
       "  FRASER SOCKEYE SALMON - LATE                   0.871233\n",
       "  FRASER SOCKEYE SALMON - SUMMER                 0.899543\n",
       "  FRASER SOCKEYE SALMON -EARLY STUART            0.917808\n",
       "  FRASER SPRING RUN 42 CHINOOK SALMON            0.971429\n",
       "  FRASER SPRING RUN 52 CHINOOK SALMON            0.933333\n",
       "  FRASER SUMMER RUN 41 CHINOOK SALMON            0.961905\n",
       "  FRASER SUMMER RUN 52 CHINOOK SALMON            0.974286\n",
       "  INNER SOUTH COAST CHUM SALMON                  1.000000\n",
       "  INTERIOR FRASER COHO SALMON                    0.949749\n",
       "  JOHNSTONE STRAIT/MAINLAND INLET COHO SALMON    0.920000\n",
       "  LOWER GEORGIA STRAIT CHINOOK SALMON            0.918033\n",
       "  MAINLAND INLET CHINOOK SALMON                  0.979167\n",
       "  MIDDLE GEORGIA STRAIT CHINOOK SALMON           0.988950\n",
       "  NASS CHINOOK SALMON                            1.000000\n",
       "  NASS SOCKEYE SALMON                            0.878049\n",
       "  PORCUPINE CHUM SALMON                          0.923077\n",
       "  SKEENA CHINOOK SALMON                          1.000000\n",
       "  SKEENA SOCKEYE SALMON                          0.973684\n",
       "  STIKINE CHINOOK SALMON                         0.851852\n",
       "  STIKINE SOCKEYE SALMON                         0.977273\n",
       "  STRAIT OF GEORGIA COHO SALMON                  0.947368\n",
       "  TAKU CHINOOK SALMON                            0.970588\n",
       "  TAKU COHO SALMON                               0.972222\n",
       "  TAKU SOCKEYE SALMON                            0.974359\n",
       "  WCVI - BARKLEY SOCKEYE SALMON                  0.984496\n",
       "  WCVI CHINOOK SALMON                            0.977273\n",
       "  WCVI COHO SALMON                               0.969697\n",
       "  YUKON RIVER CHINOOK                            1.000000\n",
       "  YUKON RIVER CHUM                               1.000000\n",
       "  Name: Escapement_Total, dtype: float64},\n",
       " {'Escapement_Total': 0.9722222222222222})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_outliers_iqr(\n",
    "    dataset_path='data/test/new Escapement Data 2022.xlsx',\n",
    "    selected_columns=['Escapement_Total'],\n",
    "    groupby_column=['SMU'],\n",
    "    threshold=1.5,\n",
    "    minimum_score= 0.85\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Salmonid Enhancement Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'TotalRelease': FACILITY_NAME      SPECIES_NAME  BROOD_YEAR\n",
       "  232nd Street Pond  Chum          1995          1.0\n",
       "                                   1996          1.0\n",
       "                                   1997          1.0\n",
       "                                   1998          1.0\n",
       "                                   1999          1.0\n",
       "                                                ... \n",
       "  Zeballos Schools   Chinook       2013          1.0\n",
       "                     Chum          2012          1.0\n",
       "                                   2019          1.0\n",
       "                                   2022          1.0\n",
       "                     Coho          2018          1.0\n",
       "  Name: TotalRelease, Length: 16564, dtype: float64},\n",
       " {'TotalRelease': 0.9448804636561217})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_outliers_iqr(\n",
    "    dataset_path='data/test/Salmonid_Enhancement_Program_Releases.xlsx',\n",
    "    selected_columns=['TotalRelease'],\n",
    "    groupby_column= ['FACILITY_NAME','SPECIES_NAME', 'BROOD_YEAR'],\n",
    "    threshold=1.5,\n",
    "    minimum_score= 0.85\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9530626211931106\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "scores = [0.9613893007870423, 0.9447359415991787]\n",
    "print(statistics.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy Type 3 (A3 Duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 1: finding duplicates\n",
    "def find_duplicates_and_percentage(dataset_path):\n",
    "\n",
    "    df = read_data(dataset_path)\n",
    "\n",
    "    # Find duplicate rows\n",
    "    duplicate_rows = df[df.duplicated(keep=False)]\n",
    "    \n",
    "    # Calculate percentage of duplicate rows\n",
    "    total_rows = len(df)\n",
    "    total_duplicate_rows = len(duplicate_rows)\n",
    "    percentage_duplicate = 1-(total_duplicate_rows / total_rows)\n",
    "    \n",
    "    # Print duplicate rows\n",
    "    print(\"Duplicate Rows:\")\n",
    "    print(duplicate_rows)\n",
    "    \n",
    "    # Print percentage of duplicate rows\n",
    "    print(f\"\\nDuplication Score: {percentage_duplicate*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "Empty DataFrame\n",
      "Columns: [Year, CU_ID, CU_Name, SMU, Species, Escapement_Wild, Escapement_Total, Recruits_Wild, Recruits_Total, IntStatus.Status, IntStatus.Year, Contact, Comments]\n",
      "Index: []\n",
      "\n",
      "Duplication Score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "find_duplicates_and_percentage(dataset_path = 'data/test/new Escapement Data 2022.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Habitat Restoration Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "Empty DataFrame\n",
      "Columns: [Unnamed: 0, site_species_id, project_name, project_description, reporting_fy, site_latitude, site_longitude, ecosystem_type, species_name, CU_Name, FULL_CU_IN, SMU_Display, SMU_ID]\n",
      "Index: []\n",
      "\n",
      "Duplication Score: 100.0%\n"
     ]
    }
   ],
   "source": [
    "find_duplicates_and_percentage(dataset_path= 'data/test/SalmonHabitatRestorationProjects_DataPortal_June_FinalFields_20240613.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Salmonid Enhancement Program (SEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "      PROGRAM_CODE         PROJ_NAME SPECIES_NAME RUN_NAME  BROOD_YEAR  \\\n",
      "83             AFS  Homalco-Taggares         Coho     Fall        1999   \n",
      "84             AFS  Homalco-Taggares         Coho     Fall        1999   \n",
      "254            AFS         Victor Cr      Sockeye     Fall        2005   \n",
      "256            AFS         Victor Cr      Sockeye     Fall        2005   \n",
      "1049           CDP       Fort Babine      Chinook   Summer        2002   \n",
      "...            ...               ...          ...      ...         ...   \n",
      "30375          PIP     Poco Hatchery         Coho     Fall        2008   \n",
      "30387          PIP     Poco Hatchery         Coho     Fall        2010   \n",
      "30388          PIP     Poco Hatchery         Coho     Fall        2010   \n",
      "32596          PIP       Terminal Cr         Coho     Fall        2006   \n",
      "32597          PIP       Terminal Cr         Coho     Fall        2006   \n",
      "\n",
      "           STOCK_NAME STOCK_PROD_AREA_CODE  STOCK_GFE_ID  \\\n",
      "83           Orford R                 JNST         816.0   \n",
      "84           Orford R                 JNST         816.0   \n",
      "254    Lagoon Cr/CCST                 CCST        1829.0   \n",
      "256    Lagoon Cr/CCST                 CCST        1829.0   \n",
      "1049         Babine R                 SKNA         592.0   \n",
      "...               ...                  ...           ...   \n",
      "30375     Coquitlam R                 LWFR           8.0   \n",
      "30387     Coquitlam R                 LWFR           8.0   \n",
      "30388     Coquitlam R                 LWFR           8.0   \n",
      "32596   Tenderfoot Cr                 GSMN         724.0   \n",
      "32597   Tenderfoot Cr                 GSMN         724.0   \n",
      "\n",
      "                   STOCK_GFE_NAME  STOCK_POP_ID  ... REL_WATERBODY_ID  \\\n",
      "83                   ORFORD RIVER       50532.0  ...              NaN   \n",
      "84                   ORFORD RIVER       50532.0  ...              NaN   \n",
      "254                  LAGOON CREEK       42740.0  ...         299869.0   \n",
      "256                  LAGOON CREEK       42740.0  ...         299869.0   \n",
      "1049   BABINE RIVER - SECTION 1-3        3255.0  ...         208377.0   \n",
      "...                           ...           ...  ...              ...   \n",
      "30375             COQUITLAM RIVER       47908.0  ...            114.0   \n",
      "30387             COQUITLAM RIVER       47908.0  ...            114.0   \n",
      "30388             COQUITLAM RIVER       47908.0  ...            114.0   \n",
      "32596            TENDERFOOT CREEK       50011.0  ...         273720.0   \n",
      "32597            TENDERFOOT CREEK       50011.0  ...         273720.0   \n",
      "\n",
      "       REL_WATERBODY_NAME                                 REL_WATERSHED_CODE  \\\n",
      "83                    NaN                                                NaN   \n",
      "84                    NaN                                                NaN   \n",
      "254                   NaN  915-486500-05300-00000-0000-0000-000-000-000-0...   \n",
      "256                   NaN  915-486500-05300-00000-0000-0000-000-000-000-0...   \n",
      "1049         BABINE RIVER  480-000000-00000-00000-0000-0000-000-000-000-0...   \n",
      "...                   ...                                                ...   \n",
      "30375     COQUITLAM RIVER  100-024500-00000-00000-0000-0000-000-000-000-0...   \n",
      "30387     COQUITLAM RIVER  100-024500-00000-00000-0000-0000-000-000-000-0...   \n",
      "30388     COQUITLAM RIVER  100-024500-00000-00000-0000-0000-000-000-000-0...   \n",
      "32596      KILLARNEY LAKE  905-074000-76000-00000-0000-0000-000-000-000-0...   \n",
      "32597      KILLARNEY LAKE  905-074000-76000-00000-0000-0000-000-000-000-0...   \n",
      "\n",
      "      REL_LATITUDE  REL_LONGITUDE RELEASE_STAGE_NAME RELEASE_YEAR  START_DATE  \\\n",
      "83       50.594884    -124.865525          Seapen 1+         2001      200105   \n",
      "84       50.594884    -124.865525          Seapen 1+         2001      200105   \n",
      "254      52.602091    -128.440007          Seapen 1+         2007    20070525   \n",
      "256      52.602091    -128.440007          Seapen 1+         2007    20070525   \n",
      "1049     55.329729    -126.631149           Smolt 1+         2004        2004   \n",
      "...            ...            ...                ...          ...         ...   \n",
      "30375    49.226489    -122.805561           Smolt 1+         2010    20100422   \n",
      "30387    49.226489    -122.805561            Fed Fry         2011    20110623   \n",
      "30388    49.226489    -122.805561            Fed Fry         2011    20110623   \n",
      "32596          NaN            NaN              Unfed         2007    20070401   \n",
      "32597          NaN            NaN              Unfed         2007    20070401   \n",
      "\n",
      "       END_DATE TotalRelease  \n",
      "83       200105         6656  \n",
      "84       200105         6656  \n",
      "254    20070525         2140  \n",
      "256    20070525         2140  \n",
      "1049       2004            0  \n",
      "...         ...          ...  \n",
      "30375  20100422          500  \n",
      "30387  20110623         8375  \n",
      "30388  20110623         8375  \n",
      "32596  20070401         4000  \n",
      "32597  20070401         4000  \n",
      "\n",
      "[150 rows x 36 columns]\n",
      "\n",
      "Duplication Score: 99.60058580748236%\n"
     ]
    }
   ],
   "source": [
    "find_duplicates_and_percentage(dataset_path='data/test/Salmonid_Enhancement_Program_Releases.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pacific Salmon Outlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "      Year                      Area  SPECIES  \\\n",
      "1378  2021  Fraser River/BC Interior  Sockeye   \n",
      "1379  2021  Fraser River/BC Interior  Sockeye   \n",
      "1470  2021               South Coast  Chinook   \n",
      "1471  2021               South Coast  Chinook   \n",
      "1472  2021               South Coast  Chinook   \n",
      "1616  2021               South Coast     Pink   \n",
      "1617  2021               South Coast     Pink   \n",
      "\n",
      "                                  SMU NAME                       CU NAME  \\\n",
      "1378  FRASER SOCKEYE SALMON - EARLY SUMMER  Francois-Early Summer Timing   \n",
      "1379  FRASER SOCKEYE SALMON - EARLY SUMMER  Francois-Early Summer Timing   \n",
      "1470                 MIDDLE GEORGIA STRAIT                           NaN   \n",
      "1471                 MIDDLE GEORGIA STRAIT                           NaN   \n",
      "1472                 MIDDLE GEORGIA STRAIT                           NaN   \n",
      "1616                      WCVI PINK SALMON         West Vancouver Island   \n",
      "1617                      WCVI PINK SALMON         West Vancouver Island   \n",
      "\n",
      "     FULL CU INDEX OUTLOOK CATEGORY  \n",
      "1378   SEL-L-06-04                2  \n",
      "1379   SEL-L-06-04                2  \n",
      "1470           NaN                3  \n",
      "1471           NaN                3  \n",
      "1472           NaN                3  \n",
      "1616           NaN   Data Deficient  \n",
      "1617           NaN   Data Deficient  \n",
      "\n",
      "Duplication Score: 99.57238851557727%\n"
     ]
    }
   ],
   "source": [
    "find_duplicates_and_percentage(dataset_path='data/test/salmonoutlook_dataportal_DRAFT_PLACEHOLDER.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crosswalk: SMU-CU-DU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "    FULL_CU_IN       CU_Display          CU_DFO_Area CU_Species  CU_Type  \\\n",
      "496      CM-46  PORCUPINE RIVER  YUKON TRANSBOUNDARY       Chum  Current   \n",
      "497      CM-46  PORCUPINE RIVER  YUKON TRANSBOUNDARY       Chum  Current   \n",
      "\n",
      "           SMU_Display      SMU_ID         SMU_DFO_Area SMU_Species  \n",
      "496  YUKON CHUM SALMON  CM-YTRA-01  YUKON TRANSBOUNDARY        Chum  \n",
      "497  YUKON CHUM SALMON  CM-YTRA-01  YUKON TRANSBOUNDARY        Chum  \n",
      "\n",
      "Duplication Score: 99.60079840319361%\n"
     ]
    }
   ],
   "source": [
    "find_duplicates_and_percentage(dataset_path='data/Pacific Salmon Population Unit Crosswalk_Final_20240513.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pacific Salmon Business Glossary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows:\n",
      "Empty DataFrame\n",
      "Columns: [Term Name\n",
      "\n",
      ", Acronym\n",
      "\n",
      ", Topic\n",
      "\n",
      ", Definition\n",
      "\n",
      ", Synonyms\n",
      "\n",
      ", Related_Term\n",
      "\n",
      "]\n",
      "Index: []\n",
      "\n",
      "Duplication Score: 100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luos\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "find_duplicates_and_percentage(dataset_path='data/test/PSSI_Salmon_Business Glossary_V1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The threshold is for removing a column that meets the threshold of the percentage of blanks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completeness_test(dataset_path, exclude_columns = [], threshold=0.75):  \n",
    "    dataset = read_data(dataset_path)\n",
    "\n",
    "    # Exclude the 'Comment' column if it exists in the dataset  \n",
    "    if 'Comment' in dataset.columns:  \n",
    "        dataset = dataset.drop(columns=['Comment'])  \n",
    "  \n",
    "    # Exclude columns in exclude_columns if they exist in the dataset    \n",
    "    dataset = dataset.drop(columns=[col for col in exclude_columns if col in dataset.columns])\n",
    "    \n",
    "    # Calculate the percentage of non-null (non-missing) values in each column  \n",
    "    is_null_percentage = dataset.isna().mean()  \n",
    "      \n",
    "    # Identify columns with non-null percentage less than or equal to the threshold  \n",
    "    columns_to_keep = is_null_percentage[is_null_percentage <= threshold].index  \n",
    "      \n",
    "    # Keep columns that exceed the threshold of non-null values  \n",
    "    dataset2 = dataset[columns_to_keep]  \n",
    "      \n",
    "    # Calculate the actual percentage of non-missing values in the dataset  \n",
    "    total_non_missing = dataset2.notna().sum().sum()  \n",
    "    total_obs = dataset2.shape[0] * dataset2.shape[1]  \n",
    "    completeness_score = total_non_missing / total_obs  \n",
    "      \n",
    "    return completeness_score  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629798335334796"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_test('data/test/2023-sep-production-plan-en.csv', threshold = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8995842553476833"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_test('data/restoration projects_dataportal.csv', threshold = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Habitat Restoration Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9475298408488063"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_test(dataset_path='data/test/salmon_projects SalmonHabitatRest DP June.csv',\n",
    "                  exclude_columns=['CU_Name', 'FULL_CU_IN', 'SMU_Display', 'SMU_ID'],\n",
    "                  threshold = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Salmonid Enhancement Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9604727880589949"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_test(dataset_path='data/test/Salmonid_Enhancement_Program_Releases.xlsx',\n",
    "                  threshold = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pacific Salmon Outlook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9515664543153853"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_test(dataset_path='data/test/salmonoutlook_dataportal_DRAFT_PLACEHOLDER.xlsx',\n",
    "                  threshold = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crosswalk: SMU-CU-DU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.932579285872699"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_test(dataset_path='data/Pacific Salmon Population Unit Crosswalk_Final_20240513.xlsx',\n",
    "                  threshold = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pacific Salmon Business Glossary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luos\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9990942028985508"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_test(dataset_path='data/test/PSSI_Salmon_Business Glossary_V1.xlsx',\n",
    "                  exclude_columns=['Acronym\\n\\n', 'Synonyms\\n\\n', 'Related_Term\\n\\n'],\n",
    "                  threshold = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeliness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def calc_timeliness(refresh_date, cycle_day):\n",
    "    refresh_date = pd.to_datetime(refresh_date)\n",
    "    unupdate_cycle = np.max([((datetime.now() - refresh_date).days/cycle_day)-1, 0])\n",
    "\n",
    "    #unupdate_cycle = np.floor((datetime.now() - refresh_date).days/cycle_day)\n",
    "    #print((datetime.now() - refresh_date).days/cycle_day)\n",
    "    return np.max([0, 100 - (unupdate_cycle * (100/3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.30136986301369"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_timeliness('2022-12-01', cycle_day=365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Reports\n",
    "Run all the functions above first before running this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that output reports can be generated through the data quality tests of\n",
    "<p>    - Consistency type 1\n",
    "<p>    - Accuracy type 2\n",
    "<p>    - Accuracy type 3\n",
    "<p>    - Completeness\n",
    "<p>          \n",
    "<p>  *Completeness test does not require an output report (just find the blanks in the dataset). The rest can be found below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency Type 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_datasets(dataset_path, column_mapping, ref_dataset_path = None):      \n",
    "    # Read the data file      \n",
    "    df = read_data(dataset_path)      \n",
    "      \n",
    "    # Initialize ref_df if a ref dataset is provided      \n",
    "    if ref_dataset_path:      \n",
    "        df_ref = read_data(ref_dataset_path)      \n",
    "        ref_data = True #Flag to indicate we are using a ref dataset      \n",
    "    else:      \n",
    "        ref_data = False #No ref dataset, compare within the same dataset      \n",
    "      \n",
    "    for selected_column, m_selected_column in column_mapping.items():        \n",
    "        if ref_data:      \n",
    "             # Compare to ref dataset        \n",
    "            unique_observations = get_names_used_for_column(df_ref, m_selected_column)    \n",
    "        else:        \n",
    "            # Use own column for comparison        \n",
    "            unique_observations = get_names_used_for_column(df, selected_column)    \n",
    "              \n",
    "        # Iterate over each row in the selected column    \n",
    "        column_results = []  \n",
    "        for value in df[selected_column]:    \n",
    "            # Check if the value exists in unique_observations and append the result to column_results  \n",
    "            if pd.isnull(value):  \n",
    "                column_results.append(False) # or True, depending on how you want to handle NaN values  \n",
    "            else:  \n",
    "                column_results.append(value in unique_observations)  \n",
    "          \n",
    "        # Add the results as a new column in the DataFrame  \n",
    "        df[selected_column + '_comparison'] = column_results  \n",
    "        \n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROGRAM_CODE</th>\n",
       "      <th>PROJ_NAME</th>\n",
       "      <th>SPECIES_NAME</th>\n",
       "      <th>RUN_NAME</th>\n",
       "      <th>BROOD_YEAR</th>\n",
       "      <th>STOCK_NAME</th>\n",
       "      <th>STOCK_PROD_AREA_CODE</th>\n",
       "      <th>STOCK_GFE_ID</th>\n",
       "      <th>STOCK_GFE_NAME</th>\n",
       "      <th>STOCK_POP_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>REL_WATERSHED_CODE</th>\n",
       "      <th>REL_LATITUDE</th>\n",
       "      <th>REL_LONGITUDE</th>\n",
       "      <th>RELEASE_STAGE_NAME</th>\n",
       "      <th>RELEASE_YEAR</th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>TotalRelease</th>\n",
       "      <th>STOCK_CU_NAME_comparison</th>\n",
       "      <th>STOCK_CU_INDEX_comparison</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFS</td>\n",
       "      <td>Emily Lk</td>\n",
       "      <td>Sockeye</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2001</td>\n",
       "      <td>Tankeeah R</td>\n",
       "      <td>CCST</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>TANKEEAH RIVER</td>\n",
       "      <td>51935.0</td>\n",
       "      <td>...</td>\n",
       "      <td>910-463800-00000-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>52.298184</td>\n",
       "      <td>-128.261590</td>\n",
       "      <td>Unfed</td>\n",
       "      <td>2002</td>\n",
       "      <td>20020401</td>\n",
       "      <td>20020402</td>\n",
       "      <td>25954</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFS</td>\n",
       "      <td>Emily Lk</td>\n",
       "      <td>Sockeye</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2002</td>\n",
       "      <td>Tankeeah R</td>\n",
       "      <td>CCST</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>TANKEEAH RIVER</td>\n",
       "      <td>51935.0</td>\n",
       "      <td>...</td>\n",
       "      <td>910-463800-00000-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>52.298184</td>\n",
       "      <td>-128.261590</td>\n",
       "      <td>Unfed</td>\n",
       "      <td>2003</td>\n",
       "      <td>20030404</td>\n",
       "      <td>20030404</td>\n",
       "      <td>41982</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFS</td>\n",
       "      <td>Emily Lk</td>\n",
       "      <td>Sockeye</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2003</td>\n",
       "      <td>Tankeeah R</td>\n",
       "      <td>CCST</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>TANKEEAH RIVER</td>\n",
       "      <td>51935.0</td>\n",
       "      <td>...</td>\n",
       "      <td>910-463800-00000-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fed Fry</td>\n",
       "      <td>2004</td>\n",
       "      <td>20040623</td>\n",
       "      <td>20040623</td>\n",
       "      <td>63829</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFS</td>\n",
       "      <td>Emily Lk</td>\n",
       "      <td>Sockeye</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2004</td>\n",
       "      <td>Tankeeah R</td>\n",
       "      <td>CCST</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>TANKEEAH RIVER</td>\n",
       "      <td>51935.0</td>\n",
       "      <td>...</td>\n",
       "      <td>910-463800-00000-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fed Fry</td>\n",
       "      <td>2005</td>\n",
       "      <td>20050316</td>\n",
       "      <td>20050316</td>\n",
       "      <td>9526</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFS</td>\n",
       "      <td>Emily Lk</td>\n",
       "      <td>Sockeye</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2005</td>\n",
       "      <td>Tankeeah R</td>\n",
       "      <td>CCST</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>TANKEEAH RIVER</td>\n",
       "      <td>51935.0</td>\n",
       "      <td>...</td>\n",
       "      <td>910-463800-00000-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>52.298184</td>\n",
       "      <td>-128.261590</td>\n",
       "      <td>Unfed</td>\n",
       "      <td>2006</td>\n",
       "      <td>20060303</td>\n",
       "      <td>20060303</td>\n",
       "      <td>64686</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37550</th>\n",
       "      <td>RRD</td>\n",
       "      <td>Yukalup Ch</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1997</td>\n",
       "      <td>Chilliwack R</td>\n",
       "      <td>LWFR</td>\n",
       "      <td>62.0</td>\n",
       "      <td>CHILLIWACK RIVER</td>\n",
       "      <td>46983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100-065700-09700-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>49.125663</td>\n",
       "      <td>-122.098166</td>\n",
       "      <td>Chan Fry</td>\n",
       "      <td>1998</td>\n",
       "      <td>19980201</td>\n",
       "      <td>19980331</td>\n",
       "      <td>300000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37551</th>\n",
       "      <td>RRD</td>\n",
       "      <td>Yukalup Ch</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1999</td>\n",
       "      <td>Chilliwack R</td>\n",
       "      <td>LWFR</td>\n",
       "      <td>62.0</td>\n",
       "      <td>CHILLIWACK RIVER</td>\n",
       "      <td>46983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100-065700-09700-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>49.125663</td>\n",
       "      <td>-122.098166</td>\n",
       "      <td>Chan Fry</td>\n",
       "      <td>2000</td>\n",
       "      <td>20000201</td>\n",
       "      <td>20000331</td>\n",
       "      <td>300000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37552</th>\n",
       "      <td>RRD</td>\n",
       "      <td>Yukalup Ch</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2001</td>\n",
       "      <td>Chilliwack R</td>\n",
       "      <td>LWFR</td>\n",
       "      <td>62.0</td>\n",
       "      <td>CHILLIWACK RIVER</td>\n",
       "      <td>46983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100-065700-09700-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>49.125663</td>\n",
       "      <td>-122.098166</td>\n",
       "      <td>Chan Fry</td>\n",
       "      <td>2002</td>\n",
       "      <td>20020201</td>\n",
       "      <td>20020331</td>\n",
       "      <td>300000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37553</th>\n",
       "      <td>RRD</td>\n",
       "      <td>Yukalup Ch</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2003</td>\n",
       "      <td>Chilliwack R</td>\n",
       "      <td>LWFR</td>\n",
       "      <td>62.0</td>\n",
       "      <td>CHILLIWACK RIVER</td>\n",
       "      <td>46983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100-065700-09700-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>49.125663</td>\n",
       "      <td>-122.098166</td>\n",
       "      <td>Chan Fry</td>\n",
       "      <td>2004</td>\n",
       "      <td>20040201</td>\n",
       "      <td>20040430</td>\n",
       "      <td>400000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37554</th>\n",
       "      <td>RRD</td>\n",
       "      <td>Yukalup Ch</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2005</td>\n",
       "      <td>Chilliwack R</td>\n",
       "      <td>LWFR</td>\n",
       "      <td>62.0</td>\n",
       "      <td>CHILLIWACK RIVER</td>\n",
       "      <td>46983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100-065700-09700-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>49.125663</td>\n",
       "      <td>-122.098166</td>\n",
       "      <td>Chan Fry</td>\n",
       "      <td>2006</td>\n",
       "      <td>20060201</td>\n",
       "      <td>20060430</td>\n",
       "      <td>400000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37555 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PROGRAM_CODE   PROJ_NAME SPECIES_NAME RUN_NAME  BROOD_YEAR  \\\n",
       "0              AFS    Emily Lk      Sockeye   Summer        2001   \n",
       "1              AFS    Emily Lk      Sockeye   Summer        2002   \n",
       "2              AFS    Emily Lk      Sockeye   Summer        2003   \n",
       "3              AFS    Emily Lk      Sockeye   Summer        2004   \n",
       "4              AFS    Emily Lk      Sockeye   Summer        2005   \n",
       "...            ...         ...          ...      ...         ...   \n",
       "37550          RRD  Yukalup Ch         Pink     Fall        1997   \n",
       "37551          RRD  Yukalup Ch         Pink     Fall        1999   \n",
       "37552          RRD  Yukalup Ch         Pink     Fall        2001   \n",
       "37553          RRD  Yukalup Ch         Pink     Fall        2003   \n",
       "37554          RRD  Yukalup Ch         Pink     Fall        2005   \n",
       "\n",
       "         STOCK_NAME STOCK_PROD_AREA_CODE  STOCK_GFE_ID    STOCK_GFE_NAME  \\\n",
       "0        Tankeeah R                 CCST        1001.0    TANKEEAH RIVER   \n",
       "1        Tankeeah R                 CCST        1001.0    TANKEEAH RIVER   \n",
       "2        Tankeeah R                 CCST        1001.0    TANKEEAH RIVER   \n",
       "3        Tankeeah R                 CCST        1001.0    TANKEEAH RIVER   \n",
       "4        Tankeeah R                 CCST        1001.0    TANKEEAH RIVER   \n",
       "...             ...                  ...           ...               ...   \n",
       "37550  Chilliwack R                 LWFR          62.0  CHILLIWACK RIVER   \n",
       "37551  Chilliwack R                 LWFR          62.0  CHILLIWACK RIVER   \n",
       "37552  Chilliwack R                 LWFR          62.0  CHILLIWACK RIVER   \n",
       "37553  Chilliwack R                 LWFR          62.0  CHILLIWACK RIVER   \n",
       "37554  Chilliwack R                 LWFR          62.0  CHILLIWACK RIVER   \n",
       "\n",
       "       STOCK_POP_ID  ...                                 REL_WATERSHED_CODE  \\\n",
       "0           51935.0  ...  910-463800-00000-00000-0000-0000-000-000-000-0...   \n",
       "1           51935.0  ...  910-463800-00000-00000-0000-0000-000-000-000-0...   \n",
       "2           51935.0  ...  910-463800-00000-00000-0000-0000-000-000-000-0...   \n",
       "3           51935.0  ...  910-463800-00000-00000-0000-0000-000-000-000-0...   \n",
       "4           51935.0  ...  910-463800-00000-00000-0000-0000-000-000-000-0...   \n",
       "...             ...  ...                                                ...   \n",
       "37550       46983.0  ...  100-065700-09700-00000-0000-0000-000-000-000-0...   \n",
       "37551       46983.0  ...  100-065700-09700-00000-0000-0000-000-000-000-0...   \n",
       "37552       46983.0  ...  100-065700-09700-00000-0000-0000-000-000-000-0...   \n",
       "37553       46983.0  ...  100-065700-09700-00000-0000-0000-000-000-000-0...   \n",
       "37554       46983.0  ...  100-065700-09700-00000-0000-0000-000-000-000-0...   \n",
       "\n",
       "       REL_LATITUDE REL_LONGITUDE RELEASE_STAGE_NAME  RELEASE_YEAR START_DATE  \\\n",
       "0         52.298184   -128.261590              Unfed          2002   20020401   \n",
       "1         52.298184   -128.261590              Unfed          2003   20030404   \n",
       "2               NaN           NaN            Fed Fry          2004   20040623   \n",
       "3               NaN           NaN            Fed Fry          2005   20050316   \n",
       "4         52.298184   -128.261590              Unfed          2006   20060303   \n",
       "...             ...           ...                ...           ...        ...   \n",
       "37550     49.125663   -122.098166           Chan Fry          1998   19980201   \n",
       "37551     49.125663   -122.098166           Chan Fry          2000   20000201   \n",
       "37552     49.125663   -122.098166           Chan Fry          2002   20020201   \n",
       "37553     49.125663   -122.098166           Chan Fry          2004   20040201   \n",
       "37554     49.125663   -122.098166           Chan Fry          2006   20060201   \n",
       "\n",
       "       END_DATE  TotalRelease  STOCK_CU_NAME_comparison  \\\n",
       "0      20020402         25954                      True   \n",
       "1      20030404         41982                      True   \n",
       "2      20040623         63829                      True   \n",
       "3      20050316          9526                      True   \n",
       "4      20060303         64686                      True   \n",
       "...         ...           ...                       ...   \n",
       "37550  19980331        300000                      True   \n",
       "37551  20000331        300000                      True   \n",
       "37552  20020331        300000                      True   \n",
       "37553  20040430        400000                      True   \n",
       "37554  20060430        400000                      True   \n",
       "\n",
       "      STOCK_CU_INDEX_comparison  \n",
       "0                          True  \n",
       "1                          True  \n",
       "2                          True  \n",
       "3                          True  \n",
       "4                          True  \n",
       "...                         ...  \n",
       "37550                      True  \n",
       "37551                      True  \n",
       "37552                      True  \n",
       "37553                      True  \n",
       "37554                      True  \n",
       "\n",
       "[37555 rows x 38 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_mapping = {'STOCK_CU_NAME':'CU_Display', 'STOCK_CU_INDEX':'FULL_CU_IN'}  #the pattern for comparison is 'dataset column' : 'reference column'\n",
    "compare_datasets(\n",
    "    dataset_path='data/test/Salmonid_Enhancement_Program_Releases.xlsx', \n",
    "    column_mapping=column_mapping, \n",
    "    ref_dataset_path = 'data/Pacific Salmon Population Unit Crosswalk_Final_20240513.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 1: Using isdigit to find non-numerical entries  \n",
    "def find_non_digits(s):    \n",
    "    # Ensure the value is treated as a string    \n",
    "    s = str(s)    \n",
    "    return [char for char in s if not (char.isdigit() or char == '.')]  \n",
    "  \n",
    "# Function 2 : Check if each row has only numbers in each selected column and add results as new columns  \n",
    "def add_only_numbers_columns(dataset_path, selected_columns):  \n",
    "    adf = read_data(dataset_path)  \n",
    "    selected_columns = [col for col in adf.columns if col in selected_columns]   \n",
    "  \n",
    "    for column_name in selected_columns:    \n",
    "        adf[column_name+'_Only_Numbers'] = adf[column_name].apply(lambda x: len(find_non_digits(x)) == 0)  \n",
    "  \n",
    "    return adf  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Legal_Name</th>\n",
       "      <th>Facility_Name</th>\n",
       "      <th>CIP_Program</th>\n",
       "      <th>FRN</th>\n",
       "      <th>LicType</th>\n",
       "      <th>LicNo</th>\n",
       "      <th>Licensee</th>\n",
       "      <th>OpGrp</th>\n",
       "      <th>FacName</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>LICENSEE_ADDRESS_LINE1</th>\n",
       "      <th>LICENSEE_ADDRESS_LINE2</th>\n",
       "      <th>LICENSEE_CITY</th>\n",
       "      <th>LICENSEE_POSTAL_CODE</th>\n",
       "      <th>LICENSEE_PROVINCE</th>\n",
       "      <th>LICENSEE_PROVINCE_CODE</th>\n",
       "      <th>LICENSEE_BUSINESS_PHONE_NUMBER</th>\n",
       "      <th>LICENSEE_EMAIL_ADDRESS</th>\n",
       "      <th>FRN_Only_Numbers</th>\n",
       "      <th>LicNo_Only_Numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4Mile Creek Enhancement Society</td>\n",
       "      <td>4 Mile Creek Hatchery / San Juan Hatchery</td>\n",
       "      <td>CEDP</td>\n",
       "      <td>8987</td>\n",
       "      <td>SEP Community Involvement</td>\n",
       "      <td>A129621</td>\n",
       "      <td>Community Advisor, Lower Van Is, Cowichan R &amp; ...</td>\n",
       "      <td>4 Mile Creek Enhancement Society</td>\n",
       "      <td>4 Mile Creek Hatchery Project</td>\n",
       "      <td>48.590000</td>\n",
       "      <td>...</td>\n",
       "      <td>5245 Trans Canada Highway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Duncan</td>\n",
       "      <td>V0R 2C0</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>BC</td>\n",
       "      <td>(250) 466-4007</td>\n",
       "      <td>Heather.Wright@dfo-mpo.gc.ca</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4Mile Creek Enhancement Society</td>\n",
       "      <td>4 Mile Creek Hatchery / San Juan Hatchery</td>\n",
       "      <td>CEDP</td>\n",
       "      <td>8988</td>\n",
       "      <td>SEP Community Involvement</td>\n",
       "      <td>129548</td>\n",
       "      <td>Community Advisor, Lower Van Is, Cowichan R &amp; ...</td>\n",
       "      <td>Port Renfrew Enhancement Society</td>\n",
       "      <td>San Juan River Seapen Project</td>\n",
       "      <td>48.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>5245 Trans Canada Highway</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Duncan</td>\n",
       "      <td>V0R 2C0</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>BC</td>\n",
       "      <td>(250) 466-4007</td>\n",
       "      <td>Heather.Wright@dfo-mpo.gc.ca</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Rocha Canada - Houston</td>\n",
       "      <td>Buck Creek Canfor Hatchery</td>\n",
       "      <td>PIP</td>\n",
       "      <td>9005</td>\n",
       "      <td>SEP Community Involvement</td>\n",
       "      <td>129533</td>\n",
       "      <td>Community Advisor, Smithers and Northwestern BC</td>\n",
       "      <td>A Rocha Canada</td>\n",
       "      <td>A Rocha Project</td>\n",
       "      <td>54.396110</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>BC</td>\n",
       "      <td>-</td>\n",
       "      <td>Jonathan.Minson@dfo-mpo.gc.ca</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbotsford Ravine Park Salmonid Enhancement So...</td>\n",
       "      <td>Ravine Park Hatchery / Matsqui Slough Watershe...</td>\n",
       "      <td>PIP</td>\n",
       "      <td>9068</td>\n",
       "      <td>SEP Community Involvement</td>\n",
       "      <td>,129606</td>\n",
       "      <td>Community Advisor, Mission/Abbotsford to past ...</td>\n",
       "      <td>Abbotsford Ravine Park Salmon Enhancement Society</td>\n",
       "      <td>Ravine Park Project</td>\n",
       "      <td>49.045270</td>\n",
       "      <td>...</td>\n",
       "      <td>4222 Columbia Valley Hwy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cultus Lake</td>\n",
       "      <td>V2R 5B6</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>BC</td>\n",
       "      <td>(604) 378-4216</td>\n",
       "      <td>Paul.Neufeld@dfo-mpo-gc.ca</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alberni Valley Enhancement Association</td>\n",
       "      <td>Jake Leyenaar Hatchery / Dave Chitty Resource ...</td>\n",
       "      <td>PIP</td>\n",
       "      <td>9006</td>\n",
       "      <td>SEP Community Involvement</td>\n",
       "      <td>129532</td>\n",
       "      <td>Community Advisor, Central W Coast of Van Is, ...</td>\n",
       "      <td>Alberni Valley Enhancement Association</td>\n",
       "      <td>Alberni Project</td>\n",
       "      <td>49.284000</td>\n",
       "      <td>...</td>\n",
       "      <td>4706 Tebo Avenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Port Alberni</td>\n",
       "      <td>V9Y 8B1</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>BC</td>\n",
       "      <td>250-918-4782</td>\n",
       "      <td>Ryan.Cyr@dfo-mpo.gc.ca</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Tsolum River Restoration Society</td>\n",
       "      <td>Tsolum River Hatchery</td>\n",
       "      <td>PIP</td>\n",
       "      <td>9078</td>\n",
       "      <td>SEP Community Involvement</td>\n",
       "      <td>129536</td>\n",
       "      <td>Community Advisor, Central E&amp;W Van Is, Nanoose...</td>\n",
       "      <td>Tsolum River Restoration Society</td>\n",
       "      <td>Tsolum River Hatchery</td>\n",
       "      <td>49.615080</td>\n",
       "      <td>...</td>\n",
       "      <td>148 Port Augusta Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comox</td>\n",
       "      <td>V9M 3N6</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>BC</td>\n",
       "      <td>(250) 465-8348</td>\n",
       "      <td>Jacob.Melville@dfo-mpo.gc.ca</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>University of Northern British Columbia</td>\n",
       "      <td>Quesnel River Research Centre</td>\n",
       "      <td>Other</td>\n",
       "      <td>9067</td>\n",
       "      <td>SEP Community Involvement</td>\n",
       "      <td>129614</td>\n",
       "      <td>Community Advisor, Central Interior: North of ...</td>\n",
       "      <td>University of Northern British Columbia, Quesn...</td>\n",
       "      <td>Quesnel River Research Centre Project</td>\n",
       "      <td>52.617440</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>BC</td>\n",
       "      <td>-</td>\n",
       "      <td>Tyler.Thibault@dfo-mpo.gc.ca</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>West Vancouver Streamkeepers Society</td>\n",
       "      <td>Nelson Creek Hatchery</td>\n",
       "      <td>PIP</td>\n",
       "      <td>9067</td>\n",
       "      <td>SEP Community Involvement</td>\n",
       "      <td>129596</td>\n",
       "      <td>Community Advisor, West Vancouver and Howe Sound</td>\n",
       "      <td>West Vancouver Streamkeepers</td>\n",
       "      <td>Nelson Creek Project</td>\n",
       "      <td>49.364840</td>\n",
       "      <td>...</td>\n",
       "      <td>4500 Capilano Park Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North Vancouver</td>\n",
       "      <td>V7R 4L3</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>BC</td>\n",
       "      <td>0</td>\n",
       "      <td>Gillian.Steele@dfo-mpo.gc.ca</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Western Forest Products</td>\n",
       "      <td>Cordy Creek Hatchery</td>\n",
       "      <td>PIP</td>\n",
       "      <td>9028</td>\n",
       "      <td>SEP Community Involvement</td>\n",
       "      <td>129878</td>\n",
       "      <td>Community Advisor, N Vancouver Island; Mainlan...</td>\n",
       "      <td>Western Forest Products</td>\n",
       "      <td>Holberg-Cordy Creek Project</td>\n",
       "      <td>50.659810</td>\n",
       "      <td>...</td>\n",
       "      <td>148 Port Augusta Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comox</td>\n",
       "      <td>V9M 3N6</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>BC</td>\n",
       "      <td>(250) 703-3270</td>\n",
       "      <td>Dave.Davies@dfo-mpo.gc.ca</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Wuikinuxv Fisheries</td>\n",
       "      <td>Percy Walkus Hatchery / Rivers Inlet Hatchery</td>\n",
       "      <td>-</td>\n",
       "      <td>9072</td>\n",
       "      <td>SEP Community Involvement</td>\n",
       "      <td>129564</td>\n",
       "      <td>Community Advisor, Central Coast, Cape Caution...</td>\n",
       "      <td>Wuikinuxv Fisheries</td>\n",
       "      <td>Rivers Inlet Project</td>\n",
       "      <td>51.011145</td>\n",
       "      <td>...</td>\n",
       "      <td>_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>BC</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Legal_Name  \\\n",
       "0                     4Mile Creek Enhancement Society   \n",
       "1                     4Mile Creek Enhancement Society   \n",
       "2                            A Rocha Canada - Houston   \n",
       "3   Abbotsford Ravine Park Salmonid Enhancement So...   \n",
       "4              Alberni Valley Enhancement Association   \n",
       "..                                                ...   \n",
       "92                   Tsolum River Restoration Society   \n",
       "93            University of Northern British Columbia   \n",
       "94               West Vancouver Streamkeepers Society   \n",
       "95                            Western Forest Products   \n",
       "96                                Wuikinuxv Fisheries   \n",
       "\n",
       "                                        Facility_Name CIP_Program   FRN  \\\n",
       "0           4 Mile Creek Hatchery / San Juan Hatchery        CEDP  8987   \n",
       "1           4 Mile Creek Hatchery / San Juan Hatchery        CEDP  8988   \n",
       "2                          Buck Creek Canfor Hatchery         PIP  9005   \n",
       "3   Ravine Park Hatchery / Matsqui Slough Watershe...         PIP  9068   \n",
       "4   Jake Leyenaar Hatchery / Dave Chitty Resource ...         PIP  9006   \n",
       "..                                                ...         ...   ...   \n",
       "92                              Tsolum River Hatchery         PIP  9078   \n",
       "93                      Quesnel River Research Centre       Other  9067   \n",
       "94                              Nelson Creek Hatchery         PIP  9067   \n",
       "95                               Cordy Creek Hatchery         PIP  9028   \n",
       "96      Percy Walkus Hatchery / Rivers Inlet Hatchery           -  9072   \n",
       "\n",
       "                      LicType    LicNo  \\\n",
       "0   SEP Community Involvement  A129621   \n",
       "1   SEP Community Involvement   129548   \n",
       "2   SEP Community Involvement   129533   \n",
       "3   SEP Community Involvement  ,129606   \n",
       "4   SEP Community Involvement   129532   \n",
       "..                        ...      ...   \n",
       "92  SEP Community Involvement   129536   \n",
       "93  SEP Community Involvement   129614   \n",
       "94  SEP Community Involvement   129596   \n",
       "95  SEP Community Involvement   129878   \n",
       "96  SEP Community Involvement   129564   \n",
       "\n",
       "                                             Licensee  \\\n",
       "0   Community Advisor, Lower Van Is, Cowichan R & ...   \n",
       "1   Community Advisor, Lower Van Is, Cowichan R & ...   \n",
       "2     Community Advisor, Smithers and Northwestern BC   \n",
       "3   Community Advisor, Mission/Abbotsford to past ...   \n",
       "4   Community Advisor, Central W Coast of Van Is, ...   \n",
       "..                                                ...   \n",
       "92  Community Advisor, Central E&W Van Is, Nanoose...   \n",
       "93  Community Advisor, Central Interior: North of ...   \n",
       "94   Community Advisor, West Vancouver and Howe Sound   \n",
       "95  Community Advisor, N Vancouver Island; Mainlan...   \n",
       "96  Community Advisor, Central Coast, Cape Caution...   \n",
       "\n",
       "                                                OpGrp  \\\n",
       "0                    4 Mile Creek Enhancement Society   \n",
       "1                    Port Renfrew Enhancement Society   \n",
       "2                                      A Rocha Canada   \n",
       "3   Abbotsford Ravine Park Salmon Enhancement Society   \n",
       "4              Alberni Valley Enhancement Association   \n",
       "..                                                ...   \n",
       "92                   Tsolum River Restoration Society   \n",
       "93  University of Northern British Columbia, Quesn...   \n",
       "94                       West Vancouver Streamkeepers   \n",
       "95                            Western Forest Products   \n",
       "96                                Wuikinuxv Fisheries   \n",
       "\n",
       "                                  FacName   Latitude  ...  \\\n",
       "0           4 Mile Creek Hatchery Project  48.590000  ...   \n",
       "1           San Juan River Seapen Project  48.550000  ...   \n",
       "2                         A Rocha Project  54.396110  ...   \n",
       "3                     Ravine Park Project  49.045270  ...   \n",
       "4                         Alberni Project  49.284000  ...   \n",
       "..                                    ...        ...  ...   \n",
       "92                  Tsolum River Hatchery  49.615080  ...   \n",
       "93  Quesnel River Research Centre Project  52.617440  ...   \n",
       "94                   Nelson Creek Project  49.364840  ...   \n",
       "95            Holberg-Cordy Creek Project  50.659810  ...   \n",
       "96                   Rivers Inlet Project  51.011145  ...   \n",
       "\n",
       "       LICENSEE_ADDRESS_LINE1 LICENSEE_ADDRESS_LINE2    LICENSEE_CITY  \\\n",
       "0   5245 Trans Canada Highway                    NaN           Duncan   \n",
       "1   5245 Trans Canada Highway                    NaN           Duncan   \n",
       "2                           _                    NaN                -   \n",
       "3    4222 Columbia Valley Hwy                    NaN      Cultus Lake   \n",
       "4            4706 Tebo Avenue                    NaN     Port Alberni   \n",
       "..                        ...                    ...              ...   \n",
       "92    148 Port Augusta Street                    NaN            Comox   \n",
       "93                          _                    NaN                -   \n",
       "94    4500 Capilano Park Road                    NaN  North Vancouver   \n",
       "95    148 Port Augusta Street                    NaN            Comox   \n",
       "96                          _                    NaN                -   \n",
       "\n",
       "   LICENSEE_POSTAL_CODE     LICENSEE_PROVINCE LICENSEE_PROVINCE_CODE  \\\n",
       "0               V0R 2C0  British Columbia                         BC   \n",
       "1               V0R 2C0  British Columbia                         BC   \n",
       "2                     -  British Columbia                         BC   \n",
       "3               V2R 5B6  British Columbia                         BC   \n",
       "4               V9Y 8B1  British Columbia                         BC   \n",
       "..                  ...                   ...                    ...   \n",
       "92              V9M 3N6  British Columbia                         BC   \n",
       "93                    -  British Columbia                         BC   \n",
       "94              V7R 4L3  British Columbia                         BC   \n",
       "95              V9M 3N6  British Columbia                         BC   \n",
       "96                    -  British Columbia                         BC   \n",
       "\n",
       "   LICENSEE_BUSINESS_PHONE_NUMBER         LICENSEE_EMAIL_ADDRESS  \\\n",
       "0                  (250) 466-4007   Heather.Wright@dfo-mpo.gc.ca   \n",
       "1                  (250) 466-4007   Heather.Wright@dfo-mpo.gc.ca   \n",
       "2                               -  Jonathan.Minson@dfo-mpo.gc.ca   \n",
       "3                  (604) 378-4216     Paul.Neufeld@dfo-mpo-gc.ca   \n",
       "4                    250-918-4782         Ryan.Cyr@dfo-mpo.gc.ca   \n",
       "..                            ...                            ...   \n",
       "92                 (250) 465-8348   Jacob.Melville@dfo-mpo.gc.ca   \n",
       "93                              -   Tyler.Thibault@dfo-mpo.gc.ca   \n",
       "94                              0   Gillian.Steele@dfo-mpo.gc.ca   \n",
       "95                 (250) 703-3270      Dave.Davies@dfo-mpo.gc.ca   \n",
       "96                              -                            NaN   \n",
       "\n",
       "   FRN_Only_Numbers LicNo_Only_Numbers  \n",
       "0              True              False  \n",
       "1              True               True  \n",
       "2              True               True  \n",
       "3              True              False  \n",
       "4              True               True  \n",
       "..              ...                ...  \n",
       "92             True               True  \n",
       "93             True               True  \n",
       "94             True               True  \n",
       "95             True               True  \n",
       "96             True               True  \n",
       "\n",
       "[97 rows x 26 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_only_numbers_columns(\n",
    "    dataset_path = 'data/test/SEP Facilities.xlsx',\n",
    "    selected_columns = ['LicNo', 'FRN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salmonid Enhancement Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROGRAM_CODE</th>\n",
       "      <th>PROJ_NAME</th>\n",
       "      <th>SPECIES_NAME</th>\n",
       "      <th>RUN_NAME</th>\n",
       "      <th>BROOD_YEAR</th>\n",
       "      <th>STOCK_NAME</th>\n",
       "      <th>STOCK_PROD_AREA_CODE</th>\n",
       "      <th>STOCK_GFE_ID</th>\n",
       "      <th>STOCK_GFE_NAME</th>\n",
       "      <th>STOCK_POP_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>REL_WATERBODY_NAME</th>\n",
       "      <th>REL_WATERSHED_CODE</th>\n",
       "      <th>REL_LATITUDE</th>\n",
       "      <th>REL_LONGITUDE</th>\n",
       "      <th>RELEASE_STAGE_NAME</th>\n",
       "      <th>RELEASE_YEAR</th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>TotalRelease</th>\n",
       "      <th>TotalRelease_Only_Numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFS</td>\n",
       "      <td>Emily Lk</td>\n",
       "      <td>Sockeye</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2001</td>\n",
       "      <td>Tankeeah R</td>\n",
       "      <td>CCST</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>TANKEEAH RIVER</td>\n",
       "      <td>51935.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TANKEEAH RIVER</td>\n",
       "      <td>910-463800-00000-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>52.298184</td>\n",
       "      <td>-128.261590</td>\n",
       "      <td>Unfed</td>\n",
       "      <td>2002</td>\n",
       "      <td>20020401</td>\n",
       "      <td>20020402</td>\n",
       "      <td>25954</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFS</td>\n",
       "      <td>Emily Lk</td>\n",
       "      <td>Sockeye</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2002</td>\n",
       "      <td>Tankeeah R</td>\n",
       "      <td>CCST</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>TANKEEAH RIVER</td>\n",
       "      <td>51935.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TANKEEAH RIVER</td>\n",
       "      <td>910-463800-00000-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>52.298184</td>\n",
       "      <td>-128.261590</td>\n",
       "      <td>Unfed</td>\n",
       "      <td>2003</td>\n",
       "      <td>20030404</td>\n",
       "      <td>20030404</td>\n",
       "      <td>41982</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFS</td>\n",
       "      <td>Emily Lk</td>\n",
       "      <td>Sockeye</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2003</td>\n",
       "      <td>Tankeeah R</td>\n",
       "      <td>CCST</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>TANKEEAH RIVER</td>\n",
       "      <td>51935.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>910-463800-00000-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fed Fry</td>\n",
       "      <td>2004</td>\n",
       "      <td>20040623</td>\n",
       "      <td>20040623</td>\n",
       "      <td>63829</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFS</td>\n",
       "      <td>Emily Lk</td>\n",
       "      <td>Sockeye</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2004</td>\n",
       "      <td>Tankeeah R</td>\n",
       "      <td>CCST</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>TANKEEAH RIVER</td>\n",
       "      <td>51935.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>910-463800-00000-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fed Fry</td>\n",
       "      <td>2005</td>\n",
       "      <td>20050316</td>\n",
       "      <td>20050316</td>\n",
       "      <td>9526</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFS</td>\n",
       "      <td>Emily Lk</td>\n",
       "      <td>Sockeye</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2005</td>\n",
       "      <td>Tankeeah R</td>\n",
       "      <td>CCST</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>TANKEEAH RIVER</td>\n",
       "      <td>51935.0</td>\n",
       "      <td>...</td>\n",
       "      <td>TANKEEAH RIVER</td>\n",
       "      <td>910-463800-00000-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>52.298184</td>\n",
       "      <td>-128.261590</td>\n",
       "      <td>Unfed</td>\n",
       "      <td>2006</td>\n",
       "      <td>20060303</td>\n",
       "      <td>20060303</td>\n",
       "      <td>64686</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37550</th>\n",
       "      <td>RRD</td>\n",
       "      <td>Yukalup Ch</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1997</td>\n",
       "      <td>Chilliwack R</td>\n",
       "      <td>LWFR</td>\n",
       "      <td>62.0</td>\n",
       "      <td>CHILLIWACK RIVER</td>\n",
       "      <td>46983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>CHILLIWACK/VEDDER RIVER</td>\n",
       "      <td>100-065700-09700-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>49.125663</td>\n",
       "      <td>-122.098166</td>\n",
       "      <td>Chan Fry</td>\n",
       "      <td>1998</td>\n",
       "      <td>19980201</td>\n",
       "      <td>19980331</td>\n",
       "      <td>300000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37551</th>\n",
       "      <td>RRD</td>\n",
       "      <td>Yukalup Ch</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1999</td>\n",
       "      <td>Chilliwack R</td>\n",
       "      <td>LWFR</td>\n",
       "      <td>62.0</td>\n",
       "      <td>CHILLIWACK RIVER</td>\n",
       "      <td>46983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>CHILLIWACK/VEDDER RIVER</td>\n",
       "      <td>100-065700-09700-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>49.125663</td>\n",
       "      <td>-122.098166</td>\n",
       "      <td>Chan Fry</td>\n",
       "      <td>2000</td>\n",
       "      <td>20000201</td>\n",
       "      <td>20000331</td>\n",
       "      <td>300000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37552</th>\n",
       "      <td>RRD</td>\n",
       "      <td>Yukalup Ch</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2001</td>\n",
       "      <td>Chilliwack R</td>\n",
       "      <td>LWFR</td>\n",
       "      <td>62.0</td>\n",
       "      <td>CHILLIWACK RIVER</td>\n",
       "      <td>46983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>CHILLIWACK/VEDDER RIVER</td>\n",
       "      <td>100-065700-09700-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>49.125663</td>\n",
       "      <td>-122.098166</td>\n",
       "      <td>Chan Fry</td>\n",
       "      <td>2002</td>\n",
       "      <td>20020201</td>\n",
       "      <td>20020331</td>\n",
       "      <td>300000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37553</th>\n",
       "      <td>RRD</td>\n",
       "      <td>Yukalup Ch</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2003</td>\n",
       "      <td>Chilliwack R</td>\n",
       "      <td>LWFR</td>\n",
       "      <td>62.0</td>\n",
       "      <td>CHILLIWACK RIVER</td>\n",
       "      <td>46983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>CHILLIWACK/VEDDER RIVER</td>\n",
       "      <td>100-065700-09700-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>49.125663</td>\n",
       "      <td>-122.098166</td>\n",
       "      <td>Chan Fry</td>\n",
       "      <td>2004</td>\n",
       "      <td>20040201</td>\n",
       "      <td>20040430</td>\n",
       "      <td>400000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37554</th>\n",
       "      <td>RRD</td>\n",
       "      <td>Yukalup Ch</td>\n",
       "      <td>Pink</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2005</td>\n",
       "      <td>Chilliwack R</td>\n",
       "      <td>LWFR</td>\n",
       "      <td>62.0</td>\n",
       "      <td>CHILLIWACK RIVER</td>\n",
       "      <td>46983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>CHILLIWACK/VEDDER RIVER</td>\n",
       "      <td>100-065700-09700-00000-0000-0000-000-000-000-0...</td>\n",
       "      <td>49.125663</td>\n",
       "      <td>-122.098166</td>\n",
       "      <td>Chan Fry</td>\n",
       "      <td>2006</td>\n",
       "      <td>20060201</td>\n",
       "      <td>20060430</td>\n",
       "      <td>400000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37555 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PROGRAM_CODE   PROJ_NAME SPECIES_NAME RUN_NAME  BROOD_YEAR  \\\n",
       "0              AFS    Emily Lk      Sockeye   Summer        2001   \n",
       "1              AFS    Emily Lk      Sockeye   Summer        2002   \n",
       "2              AFS    Emily Lk      Sockeye   Summer        2003   \n",
       "3              AFS    Emily Lk      Sockeye   Summer        2004   \n",
       "4              AFS    Emily Lk      Sockeye   Summer        2005   \n",
       "...            ...         ...          ...      ...         ...   \n",
       "37550          RRD  Yukalup Ch         Pink     Fall        1997   \n",
       "37551          RRD  Yukalup Ch         Pink     Fall        1999   \n",
       "37552          RRD  Yukalup Ch         Pink     Fall        2001   \n",
       "37553          RRD  Yukalup Ch         Pink     Fall        2003   \n",
       "37554          RRD  Yukalup Ch         Pink     Fall        2005   \n",
       "\n",
       "         STOCK_NAME STOCK_PROD_AREA_CODE  STOCK_GFE_ID    STOCK_GFE_NAME  \\\n",
       "0        Tankeeah R                 CCST        1001.0    TANKEEAH RIVER   \n",
       "1        Tankeeah R                 CCST        1001.0    TANKEEAH RIVER   \n",
       "2        Tankeeah R                 CCST        1001.0    TANKEEAH RIVER   \n",
       "3        Tankeeah R                 CCST        1001.0    TANKEEAH RIVER   \n",
       "4        Tankeeah R                 CCST        1001.0    TANKEEAH RIVER   \n",
       "...             ...                  ...           ...               ...   \n",
       "37550  Chilliwack R                 LWFR          62.0  CHILLIWACK RIVER   \n",
       "37551  Chilliwack R                 LWFR          62.0  CHILLIWACK RIVER   \n",
       "37552  Chilliwack R                 LWFR          62.0  CHILLIWACK RIVER   \n",
       "37553  Chilliwack R                 LWFR          62.0  CHILLIWACK RIVER   \n",
       "37554  Chilliwack R                 LWFR          62.0  CHILLIWACK RIVER   \n",
       "\n",
       "       STOCK_POP_ID  ...       REL_WATERBODY_NAME  \\\n",
       "0           51935.0  ...           TANKEEAH RIVER   \n",
       "1           51935.0  ...           TANKEEAH RIVER   \n",
       "2           51935.0  ...                      NaN   \n",
       "3           51935.0  ...                      NaN   \n",
       "4           51935.0  ...           TANKEEAH RIVER   \n",
       "...             ...  ...                      ...   \n",
       "37550       46983.0  ...  CHILLIWACK/VEDDER RIVER   \n",
       "37551       46983.0  ...  CHILLIWACK/VEDDER RIVER   \n",
       "37552       46983.0  ...  CHILLIWACK/VEDDER RIVER   \n",
       "37553       46983.0  ...  CHILLIWACK/VEDDER RIVER   \n",
       "37554       46983.0  ...  CHILLIWACK/VEDDER RIVER   \n",
       "\n",
       "                                      REL_WATERSHED_CODE REL_LATITUDE  \\\n",
       "0      910-463800-00000-00000-0000-0000-000-000-000-0...    52.298184   \n",
       "1      910-463800-00000-00000-0000-0000-000-000-000-0...    52.298184   \n",
       "2      910-463800-00000-00000-0000-0000-000-000-000-0...          NaN   \n",
       "3      910-463800-00000-00000-0000-0000-000-000-000-0...          NaN   \n",
       "4      910-463800-00000-00000-0000-0000-000-000-000-0...    52.298184   \n",
       "...                                                  ...          ...   \n",
       "37550  100-065700-09700-00000-0000-0000-000-000-000-0...    49.125663   \n",
       "37551  100-065700-09700-00000-0000-0000-000-000-000-0...    49.125663   \n",
       "37552  100-065700-09700-00000-0000-0000-000-000-000-0...    49.125663   \n",
       "37553  100-065700-09700-00000-0000-0000-000-000-000-0...    49.125663   \n",
       "37554  100-065700-09700-00000-0000-0000-000-000-000-0...    49.125663   \n",
       "\n",
       "      REL_LONGITUDE  RELEASE_STAGE_NAME RELEASE_YEAR START_DATE  END_DATE  \\\n",
       "0       -128.261590               Unfed         2002   20020401  20020402   \n",
       "1       -128.261590               Unfed         2003   20030404  20030404   \n",
       "2               NaN             Fed Fry         2004   20040623  20040623   \n",
       "3               NaN             Fed Fry         2005   20050316  20050316   \n",
       "4       -128.261590               Unfed         2006   20060303  20060303   \n",
       "...             ...                 ...          ...        ...       ...   \n",
       "37550   -122.098166            Chan Fry         1998   19980201  19980331   \n",
       "37551   -122.098166            Chan Fry         2000   20000201  20000331   \n",
       "37552   -122.098166            Chan Fry         2002   20020201  20020331   \n",
       "37553   -122.098166            Chan Fry         2004   20040201  20040430   \n",
       "37554   -122.098166            Chan Fry         2006   20060201  20060430   \n",
       "\n",
       "       TotalRelease TotalRelease_Only_Numbers  \n",
       "0             25954                      True  \n",
       "1             41982                      True  \n",
       "2             63829                      True  \n",
       "3              9526                      True  \n",
       "4             64686                      True  \n",
       "...             ...                       ...  \n",
       "37550        300000                      True  \n",
       "37551        300000                      True  \n",
       "37552        300000                      True  \n",
       "37553        400000                      True  \n",
       "37554        400000                      True  \n",
       "\n",
       "[37555 rows x 37 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_only_numbers_columns(\n",
    "    dataset_path = 'data/test/Salmonid_Enhancement_Program_Releases.xlsx',\n",
    "    selected_columns = ['TotalRelease'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Test Log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
